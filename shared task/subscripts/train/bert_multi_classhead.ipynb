{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "FFW8qpikSSgS"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\.local\\share\\mamba\\envs\\nlp\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from transformers import BertTokenizerFast, BertModel, get_linear_schedule_with_warmup\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "import copy\n",
    "import itertools\n",
    "import json\n",
    "from collections import Counter\n",
    "import math\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Configuration\n",
    "BERT_MODEL_NAME = 'bert-base-uncased'\n",
    "TRAIT_NAMES = ['openness', 'conscientiousness', 'extraversion', 'agreeableness', 'neuroticism', 'humility']\n",
    "NUM_TRAITS = len(TRAIT_NAMES)\n",
    "NUM_LEVELS = 3  # low, medium, high\n",
    "ORDINAL_OUTPUTS_PER_TRAIT = NUM_LEVELS - 1\n",
    "\n",
    "MAX_SEQ_LENGTH = 128\n",
    "# N_COMMENTS_TO_PROCESS will be set by grid search\n",
    "# ATTENTION_HIDDEN_DIM will be set by grid search\n",
    "# NUM_NUMERICAL_FEATURES will be determined from data\n",
    "\n",
    "# Early Stopping Configuration\n",
    "EARLY_STOPPING_PATIENCE = 3 # Number of epochs to wait for improvement before stopping\n",
    "MIN_DELTA = 0.001 # Minimum change in validation loss to be considered an improvement\n",
    "\n",
    "# --- 1. Dataset Class (Unchanged) ---\n",
    "class PersonalityDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 data: List[Dict],\n",
    "                 tokenizer: BertTokenizerFast,\n",
    "                 max_seq_length: int,\n",
    "                 trait_names: List[str],\n",
    "                 num_comments_to_process: int):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_seq_length = max_seq_length\n",
    "        self.trait_names = trait_names\n",
    "        self.num_comments_to_process = num_comments_to_process\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        user_comments_all = sample['comments']\n",
    "        numerical_features = sample.get('numerical_features', [])\n",
    "\n",
    "        if len(user_comments_all) > self.num_comments_to_process:\n",
    "            comments_to_process_or_pad = random.sample(user_comments_all, self.num_comments_to_process)\n",
    "        else:\n",
    "            comments_to_process_or_pad = user_comments_all\n",
    "\n",
    "        processed_comments_input_ids = []\n",
    "        processed_comments_attention_mask = []\n",
    "        active_comment_flags = []\n",
    "\n",
    "        num_actual_comments = len(comments_to_process_or_pad)\n",
    "\n",
    "        for i in range(self.num_comments_to_process):\n",
    "            if i < num_actual_comments:\n",
    "                comment_text = comments_to_process_or_pad[i]\n",
    "                active_comment_flags.append(True)\n",
    "            else:\n",
    "                comment_text = \"\"\n",
    "                active_comment_flags.append(False)\n",
    "\n",
    "            encoding = self.tokenizer.encode_plus(\n",
    "                comment_text, add_special_tokens=True, max_length=self.max_seq_length,\n",
    "                padding='max_length', truncation=True, return_attention_mask=True, return_tensors='pt'\n",
    "            )\n",
    "            processed_comments_input_ids.append(encoding['input_ids'].squeeze(0))\n",
    "            processed_comments_attention_mask.append(encoding['attention_mask'].squeeze(0))\n",
    "\n",
    "        input_ids_tensor = torch.stack(processed_comments_input_ids)\n",
    "        attention_mask_tensor = torch.stack(processed_comments_attention_mask)\n",
    "        comment_active_mask_tensor = torch.tensor(active_comment_flags, dtype=torch.bool)\n",
    "\n",
    "        integer_labels = []\n",
    "        for trait_name in self.trait_names:\n",
    "            label = sample['labels'][trait_name]\n",
    "            integer_labels.append(label)\n",
    "\n",
    "        return {\n",
    "            'input_ids': input_ids_tensor,\n",
    "            'attention_mask': attention_mask_tensor,\n",
    "            'comment_active_mask': comment_active_mask_tensor,\n",
    "            'numerical_features': torch.tensor(numerical_features, dtype=torch.float),\n",
    "            'labels': torch.tensor(integer_labels, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# --- 2. Model Class (Unchanged) ---\n",
    "class PersonalityModel(nn.Module):\n",
    "    def __init__(self,\n",
    "                 bert_model_name: str,\n",
    "                 num_traits: int,\n",
    "                 ordinal_outputs_per_trait: int,\n",
    "                 num_numerical_features: int = 0,\n",
    "                 n_comments_to_process: int = 3,\n",
    "                 dropout_rate: float = 0.2,\n",
    "                 attention_hidden_dim: int = 128):\n",
    "        super().__init__()\n",
    "        self.bert = BertModel.from_pretrained(bert_model_name)\n",
    "        self.n_comments_to_process = n_comments_to_process\n",
    "        self.ordinal_outputs_per_trait = ordinal_outputs_per_trait\n",
    "        self.num_numerical_features = num_numerical_features # Store for clarity\n",
    "\n",
    "        bert_hidden_size = self.bert.config.hidden_size\n",
    "\n",
    "        self.attention_w = nn.Linear(bert_hidden_size, attention_hidden_dim)\n",
    "        self.attention_v = nn.Linear(attention_hidden_dim, 1, bias=False)\n",
    "\n",
    "        self.feature_combiner_input_size = bert_hidden_size + self.num_numerical_features\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "        self.trait_classifiers = nn.ModuleList()\n",
    "        for _ in range(num_traits):\n",
    "            self.trait_classifiers.append(\n",
    "                nn.Linear(self.feature_combiner_input_size, ordinal_outputs_per_trait)\n",
    "            )\n",
    "\n",
    "    def forward(self,\n",
    "                input_ids: torch.Tensor,\n",
    "                attention_mask: torch.Tensor,\n",
    "                comment_active_mask: torch.Tensor,\n",
    "                numerical_features: Optional[torch.Tensor] = None):\n",
    "\n",
    "        batch_size = input_ids.shape[0]\n",
    "        input_ids_flat = input_ids.view(-1, input_ids.shape[-1])\n",
    "        attention_mask_flat = attention_mask.view(-1, attention_mask.shape[-1])\n",
    "\n",
    "        outputs = self.bert(input_ids=input_ids_flat, attention_mask=attention_mask_flat)\n",
    "        comment_embeddings_flat = outputs.pooler_output\n",
    "        comment_embeddings = comment_embeddings_flat.view(batch_size, self.n_comments_to_process, -1)\n",
    "\n",
    "        u = torch.tanh(self.attention_w(comment_embeddings))\n",
    "        scores = self.attention_v(u).squeeze(-1)\n",
    "        if comment_active_mask is not None:\n",
    "            scores = scores.masked_fill(~comment_active_mask, -1e9)\n",
    "        attention_weights = F.softmax(scores, dim=1)\n",
    "        attention_weights_expanded = attention_weights.unsqueeze(-1)\n",
    "        aggregated_comment_embedding = torch.sum(attention_weights_expanded * comment_embeddings, dim=1)\n",
    "\n",
    "        if numerical_features is not None and numerical_features.numel() > 0 and numerical_features.shape[1] > 0:\n",
    "            if numerical_features.shape[1] != self.num_numerical_features:\n",
    "                 print(f\"Warning: numerical_features.shape[1] ({numerical_features.shape[1]}) \"\n",
    "                       f\"does not match self.num_numerical_features ({self.num_numerical_features})\")\n",
    "            combined_features = torch.cat((aggregated_comment_embedding, numerical_features), dim=1)\n",
    "        else:\n",
    "            combined_features = aggregated_comment_embedding\n",
    "\n",
    "        combined_features_dropped = self.dropout(combined_features)\n",
    "\n",
    "        trait_specific_logits = []\n",
    "        for classifier_head in self.trait_classifiers:\n",
    "            trait_specific_logits.append(classifier_head(combined_features_dropped))\n",
    "\n",
    "        all_logits = torch.cat(trait_specific_logits, dim=1)\n",
    "        return all_logits\n",
    "\n",
    "\n",
    "# --- 3. CORAL Loss Function (Unchanged) ---\n",
    "class MultiTaskCORALLoss(nn.Module):\n",
    "    def __init__(self, num_traits: int, num_levels: int, device: torch.device, trait_importance_weights: Optional[List[float]] = None):\n",
    "        super().__init__()\n",
    "        self.num_traits = num_traits\n",
    "        self.num_levels = num_levels\n",
    "        self.ordinal_outputs_per_trait = num_levels - 1\n",
    "        self.device = device\n",
    "\n",
    "        if trait_importance_weights is not None:\n",
    "            self.trait_importance_weights = torch.tensor(trait_importance_weights, dtype=torch.float, device=self.device)\n",
    "            if len(self.trait_importance_weights) != num_traits:\n",
    "                raise ValueError(\"Length of trait_importance_weights must match num_traits.\")\n",
    "        else:\n",
    "            self.trait_importance_weights = None\n",
    "\n",
    "    def forward(self, all_logits: torch.Tensor, true_labels_int: torch.Tensor) -> torch.Tensor:\n",
    "        batch_size = all_logits.shape[0]\n",
    "        total_loss = torch.tensor(0.0, device=self.device)\n",
    "        logits_per_trait_view = all_logits.view(batch_size, self.num_traits, self.ordinal_outputs_per_trait)\n",
    "\n",
    "        for i in range(self.num_traits):\n",
    "            trait_logits = logits_per_trait_view[:, i, :]\n",
    "            trait_labels_int = true_labels_int[:, i]\n",
    "\n",
    "            levels_binary_targets = torch.zeros_like(trait_logits, device=self.device)\n",
    "            for k in range(self.ordinal_outputs_per_trait):\n",
    "                levels_binary_targets[:, k] = (trait_labels_int > k).float()\n",
    "\n",
    "            loss_trait = F.binary_cross_entropy_with_logits(\n",
    "                trait_logits, levels_binary_targets, reduction='mean'\n",
    "            )\n",
    "\n",
    "            if self.trait_importance_weights is not None:\n",
    "                total_loss += loss_trait * self.trait_importance_weights[i]\n",
    "            else:\n",
    "                total_loss += loss_trait\n",
    "\n",
    "        return total_loss / self.num_traits if self.num_traits > 0 else torch.tensor(0.0, device=self.device)\n",
    "\n",
    "# --- Prediction Conversion (Unchanged) ---\n",
    "def convert_ordinal_logits_to_predictions(logits: torch.Tensor, num_traits: int, ordinal_outputs_per_trait: int, threshold: float = 0.5) -> torch.Tensor:\n",
    "    batch_size = logits.shape[0]\n",
    "    logits_per_trait = logits.view(batch_size, num_traits, ordinal_outputs_per_trait)\n",
    "    probs = torch.sigmoid(logits_per_trait)\n",
    "    predictions = (probs > threshold).long().sum(dim=2)\n",
    "    return predictions\n",
    "\n",
    "# --- 4. Training Loop (Unchanged) ---\n",
    "def train_epoch(model, data_loader, loss_fn, optimizer, device, scheduler, verbose=True):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch_idx, batch in enumerate(data_loader):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        comment_active_mask = batch['comment_active_mask'].to(device)\n",
    "        numerical_features = batch['numerical_features'].to(device)\n",
    "        labels_int = batch['labels'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(input_ids, attention_mask, comment_active_mask, numerical_features)\n",
    "        loss = loss_fn(logits, labels_int)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "\n",
    "        if verbose and (batch_idx + 1) % 5 == 0:\n",
    "             print(f\"  Batch {batch_idx + 1}/{len(data_loader)}, Train Loss: {loss.item():.4f}\")\n",
    "\n",
    "    avg_loss = total_loss / len(data_loader) if len(data_loader) > 0 else 0\n",
    "    if verbose:\n",
    "        print(f\"Training Epoch Summary: Avg Loss: {avg_loss:.4f}\")\n",
    "    return avg_loss\n",
    "\n",
    "# --- 5. Evaluation Loop (Unchanged) ---\n",
    "def evaluate_epoch(model, data_loader, loss_fn, device, verbose=True):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(data_loader):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            comment_active_mask = batch['comment_active_mask'].to(device)\n",
    "            numerical_features = batch['numerical_features'].to(device)\n",
    "            labels_int = batch['labels'].to(device)\n",
    "\n",
    "            logits = model(input_ids, attention_mask, comment_active_mask, numerical_features)\n",
    "            loss = loss_fn(logits, labels_int)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            if verbose and (batch_idx + 1) % 5 == 0:\n",
    "                 print(f\"  Batch {batch_idx + 1}/{len(data_loader)}, Val Loss: {loss.item():.4f}\")\n",
    "\n",
    "    avg_loss = total_loss / len(data_loader) if len(data_loader) > 0 else float('inf')\n",
    "    if verbose:\n",
    "        print(f\"Validation Epoch Summary: Avg Loss: {avg_loss:.4f}\")\n",
    "    return avg_loss\n",
    "\n",
    "# --- Test Set Evaluation Function ---\n",
    "def evaluate_on_test_set(model: PersonalityModel,\n",
    "                         data_loader: DataLoader,\n",
    "                         loss_fn: MultiTaskCORALLoss,\n",
    "                         device: torch.device,\n",
    "                         num_traits: int,\n",
    "                         ordinal_outputs_per_trait: int,\n",
    "                         trait_names: List[str]) -> Tuple[Optional[float], Optional[Dict[str, float]], Optional[float], Optional[Tuple[torch.Tensor, torch.Tensor]]]:\n",
    "    \"\"\"\n",
    "    Evaluates the model on a test dataset and computes various metrics.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_predictions_list = []\n",
    "    all_true_labels_list = []\n",
    "\n",
    "    if not data_loader or len(data_loader) == 0:\n",
    "        print(\"Test data_loader is empty. Cannot evaluate on test set.\")\n",
    "        return None, None, None, None\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            comment_active_mask = batch['comment_active_mask'].to(device)\n",
    "            numerical_features = batch['numerical_features'].to(device)\n",
    "            labels_int = batch['labels'].to(device)\n",
    "\n",
    "            logits = model(input_ids, attention_mask, comment_active_mask, numerical_features)\n",
    "            loss = loss_fn(logits, labels_int)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Convert logits to class predictions\n",
    "            predictions_batch = convert_ordinal_logits_to_predictions(\n",
    "                logits.cpu(), num_traits, ordinal_outputs_per_trait\n",
    "            )\n",
    "            all_predictions_list.append(predictions_batch)\n",
    "            all_true_labels_list.append(labels_int.cpu())\n",
    "\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "\n",
    "    all_predictions_tensor = torch.cat(all_predictions_list, dim=0)\n",
    "    all_true_labels_tensor = torch.cat(all_true_labels_list, dim=0)\n",
    "\n",
    "    # Calculate Trait-wise Accuracy\n",
    "    trait_accuracies = {}\n",
    "    for i in range(num_traits):\n",
    "        correct_predictions = (all_predictions_tensor[:, i] == all_true_labels_tensor[:, i]).sum().item()\n",
    "        total_samples_for_trait = all_true_labels_tensor.shape[0]\n",
    "        accuracy = correct_predictions / total_samples_for_trait if total_samples_for_trait > 0 else 0\n",
    "        trait_accuracies[trait_names[i]] = accuracy\n",
    "\n",
    "    # Calculate Overall Exact Match Accuracy\n",
    "    # A sample is an exact match if all its traits are predicted correctly\n",
    "    correct_sample_matches = (all_predictions_tensor == all_true_labels_tensor).all(dim=1).sum().item()\n",
    "    total_samples = all_true_labels_tensor.shape[0]\n",
    "    overall_exact_match_accuracy = correct_sample_matches / total_samples if total_samples > 0 else 0\n",
    "\n",
    "    return avg_loss, trait_accuracies, overall_exact_match_accuracy, (all_predictions_tensor, all_true_labels_tensor)\n",
    "\n",
    "\n",
    "# --- Function to run training for a set of hyperparameters (Unchanged) ---\n",
    "def run_training_for_hyperparams(params: Dict,\n",
    "                                 trial_train_data: List[Dict],\n",
    "                                 trial_val_data: List[Dict],\n",
    "                                 device: torch.device) -> float:\n",
    "    # Extract params\n",
    "    learning_rate = params['learning_rate']\n",
    "    dropout_rate = params['dropout_rate']\n",
    "    batch_size = params['batch_size']\n",
    "    attention_hidden_dim = params['attention_hidden_dim']\n",
    "    n_comments_to_process = params['n_comments_to_process']\n",
    "    num_epochs_trial = params['num_epochs_trial']\n",
    "\n",
    "    print(f\"\\n--- Starting Trial with Params: {params} ---\")\n",
    "\n",
    "    # --- Initialize Tokenizer, Datasets, DataLoaders ---\n",
    "    tokenizer = BertTokenizerFast.from_pretrained(BERT_MODEL_NAME)\n",
    "\n",
    "    current_num_numerical_features = 0\n",
    "    if trial_train_data and len(trial_train_data) > 0 and trial_train_data[0].get('numerical_features'):\n",
    "        current_num_numerical_features = len(trial_train_data[0]['numerical_features'])\n",
    "\n",
    "    train_dataset = PersonalityDataset(\n",
    "        data=trial_train_data, tokenizer=tokenizer, max_seq_length=MAX_SEQ_LENGTH,\n",
    "        trait_names=TRAIT_NAMES, num_comments_to_process=n_comments_to_process\n",
    "    )\n",
    "    val_dataset = PersonalityDataset(\n",
    "        data=trial_val_data, tokenizer=tokenizer, max_seq_length=MAX_SEQ_LENGTH,\n",
    "        trait_names=TRAIT_NAMES, num_comments_to_process=n_comments_to_process\n",
    "    )\n",
    "\n",
    "    use_pin_memory = True if device.type == 'cuda' else False\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=max(1,math.floor((3/4)*os.cpu_count())), pin_memory=use_pin_memory, persistent_workers=True)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=max(1,math.floor((3/4)*os.cpu_count())), pin_memory=use_pin_memory, persistent_workers=True)\n",
    "\n",
    "    # --- Initialize Model, Loss, Optimizer ---\n",
    "    model = PersonalityModel(\n",
    "        bert_model_name=BERT_MODEL_NAME,\n",
    "        num_traits=NUM_TRAITS,\n",
    "        ordinal_outputs_per_trait=ORDINAL_OUTPUTS_PER_TRAIT,\n",
    "        num_numerical_features=current_num_numerical_features,\n",
    "        n_comments_to_process=n_comments_to_process,\n",
    "        dropout_rate=dropout_rate,\n",
    "        attention_hidden_dim=attention_hidden_dim\n",
    "    ).to(device)\n",
    "\n",
    "    model_trait_weights = [1.0, 1.0, 1.0, 1.0, 1.0, 0.4]\n",
    "    loss_fn = MultiTaskCORALLoss(\n",
    "        num_traits=NUM_TRAITS, num_levels=NUM_LEVELS, device=device,\n",
    "        trait_importance_weights=model_trait_weights\n",
    "    ).to(device)\n",
    "\n",
    "    optimizer = AdamW(model.parameters(), lr=learning_rate, eps=1e-8)\n",
    "    total_steps = len(train_dataloader) * num_epochs_trial\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=int(0.1 * total_steps) if total_steps > 0 else 0,\n",
    "        num_training_steps=total_steps\n",
    "    )\n",
    "\n",
    "    best_val_loss_trial = float('inf')\n",
    "    epochs_no_improve_trial = 0\n",
    "    trial_verbose_epoch = True\n",
    "    trial_verbose_batch = False\n",
    "\n",
    "    for epoch in range(num_epochs_trial):\n",
    "        if trial_verbose_epoch:\n",
    "            print(f\"  Epoch {epoch + 1}/{num_epochs_trial}\")\n",
    "\n",
    "        if not train_dataloader:\n",
    "            print(\"  Skipping training epoch: train_dataloader is empty.\")\n",
    "            best_val_loss_trial = float('inf')\n",
    "            break\n",
    "\n",
    "        train_loss = train_epoch(\n",
    "            model, train_dataloader, loss_fn, optimizer, device, scheduler, verbose=trial_verbose_batch\n",
    "        )\n",
    "\n",
    "        if val_dataloader and len(val_dataloader) > 0:\n",
    "            current_val_loss = evaluate_epoch(\n",
    "                model, val_dataloader, loss_fn, device, verbose=trial_verbose_batch\n",
    "            )\n",
    "            if trial_verbose_epoch:\n",
    "                 print(f\"  Params: {params}, Epoch {epoch + 1}, Train Loss: {train_loss:.4f}, Val Loss: {current_val_loss:.4f}\")\n",
    "\n",
    "            if current_val_loss < best_val_loss_trial - MIN_DELTA:\n",
    "                best_val_loss_trial = current_val_loss\n",
    "                epochs_no_improve_trial = 0\n",
    "            else:\n",
    "                epochs_no_improve_trial += 1\n",
    "\n",
    "            if epochs_no_improve_trial >= EARLY_STOPPING_PATIENCE:\n",
    "                if trial_verbose_epoch:\n",
    "                    print(f\"  Early stopping triggered for params {params} at epoch {epoch + 1}.\")\n",
    "                break\n",
    "        else:\n",
    "            best_val_loss_trial = train_loss\n",
    "            if trial_verbose_epoch:\n",
    "                print(f\"  Params: {params}, Epoch {epoch + 1}, Train Loss: {train_loss:.4f}. No validation data for this trial.\")\n",
    "\n",
    "    print(f\"--- Trial Finished for Params: {params}. Best Val Loss for this trial: {best_val_loss_trial:.4f} ---\")\n",
    "    return best_val_loss_trial\n",
    "\n",
    "def test_data_transform(path):\n",
    "    df = pd.read_csv(path)\n",
    "    cols = ['Openness', 'Conscientiousness', 'Extraversion', 'Agreeableness', 'Humility']\n",
    "    conversion = {\n",
    "        'low': 0,\n",
    "        'medium': 1,\n",
    "        'high': 2\n",
    "    }\n",
    "    df[cols] = df[cols].apply(lambda col: col.map(conversion))\n",
    "\n",
    "    #swap es to neuro\n",
    "    conversion_es_neuro = {\n",
    "        'low': 2,\n",
    "        'medium': 1,\n",
    "        'high': 0\n",
    "    }\n",
    "    df['Emotional stability'] = df['Emotional stability'].map(conversion_es_neuro)\n",
    "\n",
    "    data = []\n",
    "    for idx, row in df.iterrows():\n",
    "        comments = [row[col] for col in ['Q1','Q2','Q3']]\n",
    "        labels = {\n",
    "            'openness': row['Openness'],\n",
    "            'conscientiousness': row['Conscientiousness'],\n",
    "            'extraversion': row['Extraversion'],\n",
    "            'agreeableness': row['Agreeableness'],\n",
    "            'neuroticism': row['Emotional stability'],\n",
    "            'humility': row['Humility']\n",
    "        }\n",
    "        new_dict ={\n",
    "            'id': row['id'],\n",
    "            'comments': comments,\n",
    "            'labels': labels\n",
    "        }\n",
    "        data.append(new_dict)\n",
    "    return data\n",
    "\n",
    "class TestPersonalityDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 data: List[Dict],\n",
    "                 tokenizer, # Should be your actual tokenizer instance e.g., BertTokenizerFast\n",
    "                 max_seq_length: int,\n",
    "                 num_comments_to_process: int):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_seq_length = max_seq_length\n",
    "        self.num_comments_to_process = num_comments_to_process\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        sample = self.data[idx]\n",
    "        # Use .get() with a default empty list for robustness if 'comments' key might be missing\n",
    "        user_comments_all = sample.get('comments', [])\n",
    "        # Use .get() for numerical_features as well\n",
    "        numerical_features_list = sample.get('numerical_features', [])\n",
    "\n",
    "        # Deterministic selection of comments for testing: take the first N\n",
    "        if len(user_comments_all) > self.num_comments_to_process:\n",
    "            comments_to_process_or_pad = user_comments_all[:self.num_comments_to_process]\n",
    "        else:\n",
    "            comments_to_process_or_pad = user_comments_all\n",
    "\n",
    "        processed_comments_input_ids = []\n",
    "        processed_comments_attention_mask = []\n",
    "        active_comment_flags = []\n",
    "\n",
    "        num_actual_comments = len(comments_to_process_or_pad)\n",
    "\n",
    "        for i in range(self.num_comments_to_process):\n",
    "            if i < num_actual_comments:\n",
    "                comment_text = comments_to_process_or_pad[i]\n",
    "                active_comment_flags.append(True)\n",
    "            else:\n",
    "                # Pad with empty strings if there are fewer actual comments\n",
    "                # The tokenizer should handle empty strings (e.g., by producing [CLS], [SEP] and padding)\n",
    "                comment_text = \"\"\n",
    "                active_comment_flags.append(False)\n",
    "\n",
    "            encoding = self.tokenizer.encode_plus(\n",
    "                comment_text,\n",
    "                add_special_tokens=True,\n",
    "                max_length=self.max_seq_length,\n",
    "                padding='max_length', # Crucial to ensure all sequences have the same length\n",
    "                truncation=True,\n",
    "                return_attention_mask=True,\n",
    "                return_tensors='pt'  # Returns PyTorch tensors\n",
    "            )\n",
    "            # .squeeze(0) because encode_plus by default adds a batch dimension (e.g., [1, seq_len])\n",
    "            # and we want to stack them along a new \"number of comments\" dimension.\n",
    "            processed_comments_input_ids.append(encoding['input_ids'].squeeze(0))\n",
    "            processed_comments_attention_mask.append(encoding['attention_mask'].squeeze(0))\n",
    "\n",
    "        # Stack the list of tensors for each comment into a single tensor.\n",
    "        # input_ids will have shape: [num_comments_to_process, max_seq_length]\n",
    "        input_ids_tensor = torch.stack(processed_comments_input_ids)\n",
    "        # attention_mask will have shape: [num_comments_to_process, max_seq_length]\n",
    "        attention_mask_tensor = torch.stack(processed_comments_attention_mask)\n",
    "\n",
    "        # comment_active_mask indicates which of the 'num_comments_to_process' slots\n",
    "        # correspond to actual comments vs. padding comments.\n",
    "        # Shape: [num_comments_to_process]\n",
    "        comment_active_mask_tensor = torch.tensor(active_comment_flags, dtype=torch.bool)\n",
    "        # If your model expects float (0.0, 1.0) for masks, use dtype=torch.float\n",
    "\n",
    "        # Convert numerical features to a tensor.\n",
    "        # Ensure numerical_features_list is a list of numbers.\n",
    "        numerical_features_tensor = torch.tensor(numerical_features_list, dtype=torch.float)\n",
    "        print('Test dataset finished')\n",
    "        return {\n",
    "            'input_ids': input_ids_tensor,\n",
    "            'attention_mask': attention_mask_tensor,\n",
    "            'comment_active_mask': comment_active_mask_tensor,\n",
    "            'numerical_features': numerical_features_tensor,\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "h-8vaISSSWUC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Data loaded\n",
      "\n",
      "Loading best weights for the final model.\n",
      "\n",
      "--- Evaluating Final Model on Test Set ---\n",
      "\n",
      "Starting predictions one by one:\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "\n",
      "Processing sample 1/3...\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "\n",
      "Processing sample 2/3...\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "\n",
      "Processing sample 3/3...\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "\n",
      "Processing sample 4/3...\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "\n",
      "Processing sample 5/3...\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "\n",
      "Processing sample 6/3...\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "\n",
      "Processing sample 7/3...\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "\n",
      "Processing sample 8/3...\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "\n",
      "Processing sample 9/3...\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "\n",
      "Processing sample 10/3...\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "\n",
      "Processing sample 11/3...\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "\n",
      "Processing sample 12/3...\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "\n",
      "Processing sample 13/3...\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "\n",
      "Processing sample 14/3...\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "\n",
      "Processing sample 15/3...\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "\n",
      "Processing sample 16/3...\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "\n",
      "Processing sample 17/3...\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "\n",
      "Processing sample 18/3...\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "\n",
      "Processing sample 19/3...\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "\n",
      "Processing sample 20/3...\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "\n",
      "Processing sample 21/3...\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "\n",
      "Processing sample 22/3...\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "\n",
      "Processing sample 23/3...\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "\n",
      "Processing sample 24/3...\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "\n",
      "Processing sample 25/3...\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "\n",
      "Processing sample 26/3...\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "\n",
      "Processing sample 27/3...\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "\n",
      "Processing sample 28/3...\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "\n",
      "Processing sample 29/3...\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "\n",
      "Processing sample 30/3...\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "\n",
      "Processing sample 31/3...\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "\n",
      "Processing sample 32/3...\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "\n",
      "Processing sample 33/3...\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "\n",
      "Processing sample 34/3...\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "\n",
      "Processing sample 35/3...\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "\n",
      "Processing sample 36/3...\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "\n",
      "Processing sample 37/3...\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "\n",
      "Processing sample 38/3...\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "\n",
      "Processing sample 39/3...\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "\n",
      "Processing sample 40/3...\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "\n",
      "Processing sample 41/3...\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "\n",
      "Processing sample 42/3...\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "\n",
      "Processing sample 43/3...\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "\n",
      "Processing sample 44/3...\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "\n",
      "Processing sample 45/3...\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "\n",
      "Processing sample 46/3...\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "\n",
      "Processing sample 47/3...\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "\n",
      "Processing sample 48/3...\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "\n",
      "Processing sample 49/3...\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "\n",
      "Processing sample 50/3...\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "\n",
      "Processing sample 51/3...\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "\n",
      "Processing sample 52/3...\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "\n",
      "Processing sample 53/3...\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "\n",
      "Processing sample 54/3...\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "\n",
      "Processing sample 55/3...\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "\n",
      "Processing sample 56/3...\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "\n",
      "Processing sample 57/3...\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "\n",
      "Processing sample 58/3...\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "\n",
      "Processing sample 59/3...\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "\n",
      "Processing sample 60/3...\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "\n",
      "Processing sample 61/3...\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "\n",
      "Processing sample 62/3...\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "Test dataset finished\n",
      "\n",
      "Processing sample 63/3...\n",
      "\n",
      "Test predictions saved to 'test_predictions.csv'.\n"
     ]
    }
   ],
   "source": [
    "#uncomment to run local\n",
    "#train_mode = True\n",
    "train_mode = False\n",
    "\n",
    "if train_mode == True:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # --- Data Loading (Train and Validation) (train) ---\n",
    "    try:\n",
    "        assert 'val_data_holdout' in globals(),'pass' #CHANGE?\n",
    "        assert 'full_train_data' in globals(),'pass'\n",
    "    except:\n",
    "        try:\n",
    "            with open(f'{folder}/data/intermediate/val_data.json', 'r') as f:\n",
    "                test_data = json.load(f)\n",
    "            with open(f'{folder}/data/intermediate/train_data.json', \"r\") as f:\n",
    "                full_train_data = json.load(f)\n",
    "        except:\n",
    "            try:\n",
    "                with open('val_data.json', 'r') as f:\n",
    "                    test_data = json.load(f)\n",
    "                with open('train_data.json', \"r\") as f:\n",
    "                    full_train_data = json.load(f)\n",
    "            except:\n",
    "                exit()\n",
    "\n",
    "    if not full_train_data:\n",
    "        print(\"Error: full_train_data is empty or failed to load properly. Exiting.\")\n",
    "        exit()\n",
    "\n",
    "    #val_data_holdout\n",
    "    val_holdout_test_size = 0.1\n",
    "    remaining_for_grid_search, val_data_holdout = train_test_split(\n",
    "    full_train_data,\n",
    "    test_size=val_holdout_test_size,\n",
    "    random_state=42\n",
    "    )\n",
    "\n",
    "    NUM_NUMERICAL_FEATURES = 0\n",
    "    if remaining_for_grid_search[0].get('numerical_features') is not None:\n",
    "        NUM_NUMERICAL_FEATURES = len(remaining_for_grid_search[0]['numerical_features'])\n",
    "        print(f\"Number of numerical features detected in full_train_data: {NUM_NUMERICAL_FEATURES}\")\n",
    "    else:\n",
    "        print(\"No 'numerical_features' key found in the first sample of full_train_data. Assuming 0 numerical features.\")\n",
    "\n",
    "    print(f\"Sample full_train_data point (user_id: {remaining_for_grid_search[0].get('user_id', 'N/A')}, num_comments: {len(remaining_for_grid_search[0].get('comments', []))})\")\n",
    "\n",
    "    # --- Stratified Split for Grid Search ---\n",
    "    traits_for_stratification = ['extraversion','openness']\n",
    "    composite_labels = []\n",
    "    valid_samples_for_strat = [] # To ensure full_train_data and composite_labels align\n",
    "\n",
    "    for sample in remaining_for_grid_search:\n",
    "        try:\n",
    "            label_str = \"-\".join([str(sample['labels'][trait]) for trait in sorted(traits_for_stratification)])\n",
    "            composite_labels.append(label_str)\n",
    "            valid_samples_for_strat.append(sample)\n",
    "        except KeyError as e:\n",
    "            print(f\"Warning: Missing trait {e} in labels for sample: {sample.get('user_id', 'Unknown User')}. Skipping this sample for stratification.\")\n",
    "\n",
    "    full_train_data_for_split = valid_samples_for_strat # Use only samples with valid labels for stratification\n",
    "    composite_labels_np = np.array(composite_labels)\n",
    "\n",
    "    if not full_train_data_for_split:\n",
    "        print(\"Error: No valid samples remaining after checking for stratification labels. Exiting.\")\n",
    "        exit()\n",
    "\n",
    "    print(f\"Distribution of composite labels for traits {traits_for_stratification} (used for splitting {len(full_train_data_for_split)} samples):\")\n",
    "    label_counts = Counter(composite_labels_np)\n",
    "    print(label_counts)\n",
    "\n",
    "    min_samples_per_stratum = 2\n",
    "    small_strata = {k: v for k, v in label_counts.items() if v < min_samples_per_stratum}\n",
    "    if small_strata:\n",
    "        print(f\"WARNING: The following strata have fewer than {min_samples_per_stratum} samples: {small_strata}\")\n",
    "        print(\"Stratified splitting might fail or be unreliable if test_size is too large for these small strata.\")\n",
    "\n",
    "    grid_search_train_data, grid_search_val_data = [], []\n",
    "    try:\n",
    "        if len(composite_labels_np) > 0 and len(full_train_data_for_split) == len(composite_labels_np):\n",
    "            grid_search_train_data, grid_search_val_data = train_test_split(\n",
    "                full_train_data_for_split,\n",
    "                test_size=0.20,\n",
    "                random_state=42,\n",
    "                stratify=composite_labels_np\n",
    "            )\n",
    "            print(f\"\\nSuccessfully performed stratified split.\")\n",
    "            print(f\"Size of data for grid search training: {len(grid_search_train_data)}\")\n",
    "            print(f\"Size of data for grid search validation: {len(grid_search_val_data)}\")\n",
    "        else:\n",
    "             raise ValueError(\"Composite labels and data mismatch after filtering, or data is empty. Cannot stratify.\")\n",
    "    except ValueError as e:\n",
    "        print(f\"\\nError during stratified split with composite labels: {e}\")\n",
    "        print(\"Falling back to stratifying by the first trait ('extraversion') or random split.\")\n",
    "        try:\n",
    "            first_trait_labels = np.array([sample['labels'][traits_for_stratification[0]] for sample in full_train_data_for_split])\n",
    "            grid_search_train_data, grid_search_val_data = train_test_split(\n",
    "                full_train_data_for_split, test_size=0.20, random_state=42, stratify=first_trait_labels\n",
    "            )\n",
    "            print(f\"Fallback (single trait stratification): Training size: {len(grid_search_train_data)}, Val size: {len(grid_search_val_data)}\")\n",
    "        except Exception as fallback_e:\n",
    "            print(f\"Fallback stratification also failed: {fallback_e}. Using random split.\")\n",
    "            grid_search_train_data, grid_search_val_data = train_test_split(\n",
    "                full_train_data_for_split, test_size=0.20, random_state=42\n",
    "            )\n",
    "            print(f\"Fallback (random split): Training size: {len(grid_search_train_data)}, Val size: {len(grid_search_val_data)}\")\n",
    "\n",
    "    if not grid_search_train_data or not grid_search_val_data:\n",
    "        print(\"Error: Grid search training or validation data is empty after splits. Exiting.\")\n",
    "        exit()\n",
    "\n",
    "    # --- Hyperparameter Grid Definition ---\n",
    "    param_grid = {\n",
    "        'learning_rate': [2e-5, 5e-5],\n",
    "        'dropout_rate': [0.1, 0.2],\n",
    "        'batch_size': [16],\n",
    "        'attention_hidden_dim': [64, 128],\n",
    "        'n_comments_to_process': [3, 4],\n",
    "        'num_epochs_trial': [5]\n",
    "    }\n",
    "\n",
    "    keys, values = zip(*param_grid.items())\n",
    "    hyperparameter_combinations = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "    print(f\"\\nStarting Grid Search. Total combinations: {len(hyperparameter_combinations)}\")\n",
    "\n",
    "    best_overall_val_loss = float('inf')\n",
    "    best_hyperparams = None\n",
    "    results = []\n",
    "\n",
    "    for i, params_combo in enumerate(hyperparameter_combinations):\n",
    "        print(f\"\\nGRID SEARCH TRIAL {i+1}/{len(hyperparameter_combinations)}\")\n",
    "        current_trial_val_loss = run_training_for_hyperparams(\n",
    "            params_combo, grid_search_train_data, grid_search_val_data, device\n",
    "        )\n",
    "        results.append({'params': params_combo, 'val_loss': current_trial_val_loss})\n",
    "\n",
    "        if current_trial_val_loss < best_overall_val_loss:\n",
    "            best_overall_val_loss = current_trial_val_loss\n",
    "            best_hyperparams = params_combo\n",
    "            print(f\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "            print(f\"!!! New best overall validation loss: {best_overall_val_loss:.4f} with params: {best_hyperparams} !!!\")\n",
    "            print(f\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "\n",
    "    print(\"\\n--- Grid Search Finished ---\")\n",
    "    print(f\"Best overall validation loss: {best_overall_val_loss:.4f}\")\n",
    "    print(f\"Best hyperparameters: {best_hyperparams}\")\n",
    "\n",
    "    print(\"\\nAll Grid Search Results (sorted by validation loss):\")\n",
    "    for res in sorted(results, key=lambda x: x['val_loss']):\n",
    "        print(f\"  Params: {res['params']}, Val Loss: {res['val_loss']:.4f}\")\n",
    "\n",
    "    # --- Train final model with best hyperparameters ---\n",
    "    if best_hyperparams:\n",
    "        with open('best_hyperparams.json', 'w') as f:\n",
    "            json.dump(best_hyperparams, f)\n",
    "        print(\"\\n--- Training a final model with the best hyperparameters ---\")\n",
    "\n",
    "        FINAL_MODEL_EPOCHS = best_hyperparams.get('num_epochs_trial', 10)\n",
    "        print(f\"Using best_hyperparams: {best_hyperparams} for up to {FINAL_MODEL_EPOCHS} epochs for the final model.\")\n",
    "\n",
    "        final_n_comments = best_hyperparams['n_comments_to_process']\n",
    "        final_batch_size = best_hyperparams['batch_size']\n",
    "\n",
    "        tokenizer = BertTokenizerFast.from_pretrained(BERT_MODEL_NAME)\n",
    "\n",
    "        final_train_dataset = PersonalityDataset(\n",
    "            data=full_train_data, # Train final model on ALL original training data\n",
    "            tokenizer=tokenizer, max_seq_length=MAX_SEQ_LENGTH,\n",
    "            trait_names=TRAIT_NAMES, num_comments_to_process=final_n_comments\n",
    "        )\n",
    "        final_val_dataset = PersonalityDataset(\n",
    "            data=val_data_holdout,\n",
    "            tokenizer=tokenizer, max_seq_length=MAX_SEQ_LENGTH,\n",
    "            trait_names=TRAIT_NAMES, num_comments_to_process=final_n_comments\n",
    "        )\n",
    "        use_pin_memory = True if device.type == 'cuda' else False\n",
    "        final_train_dataloader = DataLoader(final_train_dataset, batch_size=final_batch_size, shuffle=True, num_workers=max(1,math.floor((3/4)*os.cpu_count())), pin_memory=use_pin_memory, persistent_workers=True)\n",
    "        final_val_dataloader = DataLoader(final_val_dataset, batch_size=final_batch_size, shuffle=False, num_workers=max(1,math.floor((3/4)*os.cpu_count())), pin_memory=use_pin_memory, persistent_workers=True)\n",
    "\n",
    "        final_model = PersonalityModel(\n",
    "            bert_model_name=BERT_MODEL_NAME,\n",
    "            num_traits=NUM_TRAITS,\n",
    "            ordinal_outputs_per_trait=ORDINAL_OUTPUTS_PER_TRAIT,\n",
    "            num_numerical_features=NUM_NUMERICAL_FEATURES,\n",
    "            n_comments_to_process=best_hyperparams['n_comments_to_process'],\n",
    "            dropout_rate=best_hyperparams['dropout_rate'],\n",
    "            attention_hidden_dim=best_hyperparams['attention_hidden_dim']\n",
    "        ).to(device)\n",
    "\n",
    "        final_loss_fn = MultiTaskCORALLoss(\n",
    "            num_traits=NUM_TRAITS, num_levels=NUM_LEVELS, device=device,\n",
    "            trait_importance_weights=[1.0, 1.0, 1.0, 1.0, 1.0, 0.4]\n",
    "        ).to(device)\n",
    "\n",
    "        final_optimizer = AdamW(final_model.parameters(), lr=best_hyperparams['learning_rate'], eps=1e-8)\n",
    "\n",
    "        final_total_steps = len(final_train_dataloader) * FINAL_MODEL_EPOCHS\n",
    "        final_scheduler = get_linear_schedule_with_warmup(\n",
    "            final_optimizer,\n",
    "            num_warmup_steps=int(0.1 * final_total_steps) if final_total_steps > 0 else 0,\n",
    "            num_training_steps=final_total_steps\n",
    "        )\n",
    "\n",
    "        best_final_model_val_loss = float('inf')\n",
    "        epochs_no_improve_final = 0\n",
    "        best_final_model_state_dict = None\n",
    "\n",
    "        for epoch in range(FINAL_MODEL_EPOCHS):\n",
    "            print(f\"\\n--- Final Model Training Epoch {epoch + 1}/{FINAL_MODEL_EPOCHS} ---\")\n",
    "            train_loss = train_epoch(final_model, final_train_dataloader, final_loss_fn, final_optimizer, device, final_scheduler, verbose=True)\n",
    "\n",
    "            if final_val_dataloader and len(final_val_dataloader) > 0:\n",
    "                current_val_loss = evaluate_epoch(final_model, final_val_dataloader, final_loss_fn, device, verbose=True)\n",
    "                print(f\"Epoch {epoch + 1}: Train Loss: {train_loss:.4f}, Val Loss: {current_val_loss:.4f}\")\n",
    "\n",
    "                if current_val_loss < best_final_model_val_loss - MIN_DELTA:\n",
    "                    best_final_model_val_loss = current_val_loss\n",
    "                    epochs_no_improve_final = 0\n",
    "                    best_final_model_state_dict = copy.deepcopy(final_model.state_dict())\n",
    "                    print(f\"Validation loss improved to {best_final_model_val_loss:.4f}. Saving model state.\")\n",
    "                else:\n",
    "                    epochs_no_improve_final += 1\n",
    "\n",
    "                if epochs_no_improve_final >= EARLY_STOPPING_PATIENCE:\n",
    "                    print(f\"\\nEarly stopping triggered for final model after {epoch + 1} epochs.\")\n",
    "                    break\n",
    "            else:\n",
    "                print(f\"Epoch {epoch + 1}: Train Loss: {train_loss:.4f}. No validation data for early stopping final model.\")\n",
    "                best_final_model_state_dict = copy.deepcopy(final_model.state_dict())\n",
    "\n",
    "\n",
    "        if best_final_model_state_dict:\n",
    "            print(\"\\nLoading best weights for the final model.\")\n",
    "            final_model.load_state_dict(best_final_model_state_dict)\n",
    "            torch.save(best_final_model_state_dict, \"best_final_model.pth\")\n",
    "            print(\"Saved best final model state_dict to best_final_model.pth\")\n",
    "\n",
    "        print(\"\\nFinal model training finished or early stopped.\")\n",
    "\n",
    "\n",
    "\n",
    "        # --- NEW: Evaluate Final Model on Test Set ---\n",
    "        print(\"\\n--- Evaluating Final Model on Test Set ---\")\n",
    "\n",
    "        if test_data:\n",
    "            # Check consistency of numerical features in test_data\n",
    "            # This is a simple check on the first item. More robust checks might be needed.\n",
    "            if test_data[0].get('numerical_features') is not None:\n",
    "                num_feat_test = len(test_data[0]['numerical_features'])\n",
    "                if num_feat_test != NUM_NUMERICAL_FEATURES:\n",
    "                    print(f\"WARNING: Test data has {num_feat_test} numerical features, but model was trained with {NUM_NUMERICAL_FEATURES}.\")\n",
    "                    print(\"This might lead to errors or unexpected behavior during evaluation.\")\n",
    "            elif NUM_NUMERICAL_FEATURES > 0:\n",
    "                 print(f\"WARNING: Model was trained with {NUM_NUMERICAL_FEATURES} numerical features, but test data sample seems to have none.\")\n",
    "\n",
    "\n",
    "            test_dataset = PersonalityDataset(\n",
    "                data=test_data,\n",
    "                tokenizer=tokenizer,\n",
    "                max_seq_length=MAX_SEQ_LENGTH,\n",
    "                trait_names=TRAIT_NAMES,\n",
    "                num_comments_to_process=best_hyperparams['n_comments_to_process'] # Use best n_comments\n",
    "            )\n",
    "            test_dataloader = DataLoader(\n",
    "                test_dataset,\n",
    "                batch_size=best_hyperparams['batch_size'], # Use best batch_size\n",
    "                shuffle=False, # No need to shuffle for testing\n",
    "                num_workers=max(1,math.floor((3/4)*os.cpu_count())),\n",
    "                pin_memory=use_pin_memory,\n",
    "                persistent_workers=True if use_pin_memory else False\n",
    "            )\n",
    "\n",
    "            if test_dataloader and len(test_dataloader) > 0:\n",
    "                test_loss, test_trait_accuracies, test_overall_accuracy, (test_preds, test_true) = evaluate_on_test_set(\n",
    "                    model=final_model,\n",
    "                    data_loader=test_dataloader,\n",
    "                    loss_fn=final_loss_fn, # Re-use loss_fn from final model training\n",
    "                    device=device,\n",
    "                    num_traits=NUM_TRAITS,\n",
    "                    ordinal_outputs_per_trait=ORDINAL_OUTPUTS_PER_TRAIT,\n",
    "                    trait_names=TRAIT_NAMES\n",
    "                )\n",
    "\n",
    "                if test_loss is not None:\n",
    "                    print(f\"\\nTest Set Evaluation Results:\")\n",
    "                    print(f\"  Average Test Loss: {test_loss:.4f}\")\n",
    "                    print(f\"  Overall Exact Match Accuracy: {test_overall_accuracy:.4f}\")\n",
    "                    print(f\"  Trait-wise Accuracies:\")\n",
    "                    for trait, acc in test_trait_accuracies.items():\n",
    "                        print(f\"    {trait}: {acc:.4f}\")\n",
    "\n",
    "                    # You can also save or further analyze test_preds and test_true if needed\n",
    "                    # print(f\"Test Predictions (first 5): \\n{test_preds[:5]}\")\n",
    "                    # print(f\"Test True Labels (first 5): \\n{test_true[:5]}\")\n",
    "                else:\n",
    "                    print(\"Test evaluation could not be completed (e.g., dataloader was empty after all).\")\n",
    "            else:\n",
    "                print(\"Test DataLoader is empty. Skipping test evaluation.\")\n",
    "        else:\n",
    "            print(\"Test data is empty or not loaded. Skipping test set evaluation.\")\n",
    "        # --- END NEW TEST SET EVALUATION ---\n",
    "\n",
    "    else:\n",
    "        print(\"\\nNo best hyperparameters found. Final model not trained. Test set evaluation skipped.\")\n",
    "\n",
    "    print(\"\\n--- Script Finished ---\")\n",
    "\n",
    "\n",
    "\n",
    "elif train_mode == False: #----------------------------------------------------------------------------------------------------------------------------------------- EVAL MODE\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    use_pin_memory = True if device.type == 'cuda' else False\n",
    "    print(f\"Using device: {device}\")\n",
    "    #test data\n",
    "    def real_test_data_transform(path):\n",
    "        df = pd.read_csv(path)\n",
    "        output = []\n",
    "        for idx, row in df.iterrows():\n",
    "                id = row['id']\n",
    "                comments = [row['Q1'], row['Q2'], row['Q3']]\n",
    "                new_entry = {\n",
    "                    'id': id,\n",
    "                    'comments': comments\n",
    "                }\n",
    "                output.append(new_entry)\n",
    "        return output\n",
    "\n",
    "    test_data = real_test_data_transform(r'..\\..\\data\\test_data_a.csv')\n",
    "    print('Data loaded')\n",
    "    NUM_NUMERICAL_FEATURES = 0\n",
    "    #LOAD BEST HYPERPARAMETERS\n",
    "    best_hyperparams = {\"learning_rate\": 5e-05, \"dropout_rate\": 0.1, \"batch_size\": 16, \"attention_hidden_dim\": 64, \"n_comments_to_process\": 4, \"num_epochs_trial\": 5}\n",
    "\n",
    "    #LOAD model\n",
    "    final_model = PersonalityModel(\n",
    "        bert_model_name=BERT_MODEL_NAME,\n",
    "        num_traits=NUM_TRAITS,\n",
    "        ordinal_outputs_per_trait=ORDINAL_OUTPUTS_PER_TRAIT,\n",
    "        num_numerical_features=NUM_NUMERICAL_FEATURES,\n",
    "        n_comments_to_process=3,\n",
    "        dropout_rate=best_hyperparams['dropout_rate'],\n",
    "        attention_hidden_dim=best_hyperparams['attention_hidden_dim']\n",
    "    ).to(device)\n",
    "\n",
    "    tokenizer = BertTokenizerFast.from_pretrained(BERT_MODEL_NAME)\n",
    "\n",
    "    #load state dict\n",
    "    print(\"\\nLoading best weights for the final model.\")\n",
    "    final_model.load_state_dict(torch.load(r\"..\\..\\best_final_model.pth\", map_location=device))\n",
    "\n",
    "    # --- Evaluate Final Model on Test Set ---\n",
    "    print(\"\\n--- Evaluating Final Model on Test Set ---\")\n",
    "    if test_data:\n",
    "        # Check consistency of numerical features in test_data\n",
    "        if test_data[0].get('numerical_features') is not None:\n",
    "            num_feat_test = len(test_data[0]['numerical_features'])\n",
    "            if num_feat_test != NUM_NUMERICAL_FEATURES:\n",
    "                print(f\"WARNING: Test data has {num_feat_test} numerical features, but model was trained with {NUM_NUMERICAL_FEATURES}.\")\n",
    "                print(\"This might lead to errors or unexpected behavior during evaluation.\")\n",
    "        elif NUM_NUMERICAL_FEATURES > 0:\n",
    "                print(f\"WARNING: Model was trained with {NUM_NUMERICAL_FEATURES} numerical features, but test data sample seems to have none.\")\n",
    "\n",
    "\n",
    "        test_dataset = TestPersonalityDataset(\n",
    "            data=test_data,\n",
    "            tokenizer=tokenizer,\n",
    "            max_seq_length=MAX_SEQ_LENGTH,\n",
    "            num_comments_to_process=3\n",
    "        )\n",
    "        test_dataloader = DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size=16,\n",
    "            shuffle=False, # No need to shuffle for testing\n",
    "            num_workers=0,#max(1,math.floor((3/4)*os.cpu_count())),\n",
    "            pin_memory=False,#use_pin_memory,\n",
    "            persistent_workers=False#True if use_pin_memory else False\n",
    "        )\n",
    "        #START TRY 3\n",
    "        # --- Prediction Loop ---\n",
    "        final_model.eval()\n",
    "        all_predictions_list = []\n",
    "        all_original_indices = [] # To map predictions back to original data if needed\n",
    "\n",
    "        print(\"\\nStarting predictions one by one:\")\n",
    "        with torch.no_grad():\n",
    "            for i, batch in enumerate(test_dataloader):\n",
    "                print(f\"\\nProcessing sample {i + 1}/{len(test_dataloader)//16}...\")\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                comment_active_mask = batch['comment_active_mask'].to(device)\n",
    "                numerical_features = batch['numerical_features'].to(device)\n",
    "\n",
    "                # --- Model Forward Pass ---\n",
    "                logits_batch = final_model(input_ids, attention_mask, comment_active_mask, numerical_features)\n",
    "                # logits shape will be [16, NUM_TRAITS * ORDINAL_OUTPUTS_PER_TRAIT] because batch_size=1\n",
    "\n",
    "                # --- Convert Logits to Predictions ---\n",
    "                # predictions_batch will be for this single sample.\n",
    "                # Expected shape: [1, NUM_TRAITS]\n",
    "                predictions_batch_tensor = convert_ordinal_logits_to_predictions(\n",
    "                    logits_batch.cpu(), NUM_TRAITS, ORDINAL_OUTPUTS_PER_TRAIT\n",
    "                )\n",
    "                # predictions_for_current_sample_tensor shape is [16, NUM_TRAITS]\n",
    "\n",
    "                # If you want to work with the prediction for this specific sample immediately:\n",
    "                # .squeeze(0) removes the batch dimension of 1.\n",
    "                # .tolist() converts the tensor to a Python list.\n",
    "                all_predictions_list.extend(predictions_batch_tensor.tolist())\n",
    "\n",
    "    if all_predictions_list:\n",
    "        if len(all_predictions_list) == len(test_data):\n",
    "            test_df = pd.read_csv(r'..\\..\\data\\test_data_a.csv')\n",
    "            preds_df = test_df.copy()\n",
    "            clean_traits = ['Openness', 'Conscientiousness', 'Extraversion', 'Agreeableness', 'Emotional stability', 'Humility']\n",
    "            preds = pd.DataFrame(all_predictions_list, columns=TRAIT_NAMES)\n",
    "            for c_trait, trait in zip(clean_traits, TRAIT_NAMES):\n",
    "                if trait == 'neuroticism':\n",
    "                    preds_df[c_trait] = preds[trait].apply(lambda x: 'low' if x == 2 else ('medium' if x == 1 else 'high'))\n",
    "                else:\n",
    "                    preds_df[c_trait] = preds[trait].apply(lambda x: 'low' if x == 0 else ('medium' if x == 1 else 'high'))\n",
    "            with open('test_predictions.csv', 'w') as f:\n",
    "                preds_df.to_csv(f, index=False)\n",
    "            print(\"\\nTest predictions saved to 'test_predictions.csv'.\")\n",
    "            \n",
    "\n",
    "    else:\n",
    "        print(\"Test data is empty or not loaded. Skipping test set evaluation.\")\n",
    "else:\n",
    "  print('ERROR: Neither train or test mode.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPAVdKpT/rWvKPYwXenSyCt",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
