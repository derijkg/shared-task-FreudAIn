{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["lMSj7JSOBZp4"],"mount_file_id":"1VPx8jGDrMd6p-wVId5Mp1JMsPwNLiEt9","authorship_tag":"ABX9TyOUa2AFQ12MxWP6Gxdw+dfU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"df942953e582463795f2add818b78b66":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d8a00e85ccd645f8bd12457db81c0d43","IPY_MODEL_7aa60d7cfbf54872b72c4b0bedf1b3f2","IPY_MODEL_1371e57b49334fafa19c60b3af49ac87"],"layout":"IPY_MODEL_9a2f69acff224a599da9641b58309ddd"}},"d8a00e85ccd645f8bd12457db81c0d43":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4c72890d7f9d4d3b83f5d724f8da56a6","placeholder":"​","style":"IPY_MODEL_34e37c606a4d41fcb83667e587a5d6a3","value":"Loading checkpoint shards: 100%"}},"7aa60d7cfbf54872b72c4b0bedf1b3f2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_af2373f62b6b4e4285270918f5336dd1","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_666487c81a9343f591690be35208dbca","value":2}},"1371e57b49334fafa19c60b3af49ac87":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_68faeff657564b5792c05870a612ec44","placeholder":"​","style":"IPY_MODEL_7a0386db4b4c4ae983a908a195be0cb4","value":" 2/2 [00:22&lt;00:00, 10.41s/it]"}},"9a2f69acff224a599da9641b58309ddd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4c72890d7f9d4d3b83f5d724f8da56a6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"34e37c606a4d41fcb83667e587a5d6a3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"af2373f62b6b4e4285270918f5336dd1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"666487c81a9343f591690be35208dbca":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"68faeff657564b5792c05870a612ec44":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7a0386db4b4c4ae983a908a195be0cb4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["#check state\n","import json\n","import pandas as pd\n","totally_random = 42\n","try:\n","  assert 'authors' in globals(), \"no data to work with, run previous cell or place intermediate data in data/intermediate\"\n","  data_path_val = f'{folder}/data/val_data_realvalued.csv'\n","  data_path_out = f'{folder}/data/intermediate/humility_added.json'\n","  from_nb = 'var'\n","except:\n","  try:\n","    data_path_in = f'{folder}/data/intermediate/langdetect.json'\n","    data_path_val = f'{folder}/data/val_data_realvalued.csv'\n","    data_path_out = f'{folder}/data/intermediate/humility_added.json'\n","    from_nb = 'save'\n","  except:\n","    folder_local = '/content/drive/MyDrive/digital text analysis/NLP/shared task'\n","    data_path_in = f'{folder_local}/data/intermediate/langdetect.json'\n","    data_path_out = f'{folder_local}/data/intermediate/humility_added.json'\n","    data_path_val = f'{folder_local}/data/val_data_realvalued.csv'\n","    from_nb = 'local'\n","\n","try:\n","  assert 'skip_gated_model' in globals(), 'pass'\n","except:\n","  skip_gated_model = False\n","\n","#load\n","if from_nb == 'var':\n","  pass\n","elif from_nb in ['save', 'local']:\n","  try:\n","    with open(data_path_in, 'r', encoding='utf-8') as f:\n","      authors = json.load(f)\n","  except:\n","    raise Exception('no authors variable or save detected')\n","else:\n","  raise Exception('no authors variable or save detected')\n","\n","print(f'NB loaded in {from_nb}')\n"],"metadata":{"id":"dZC6VobqDPGj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1747707345571,"user_tz":-120,"elapsed":17460,"user":{"displayName":"Geran De Rijk","userId":"14984877830666793525"}},"outputId":"e179eac0-918f-4834-85f8-d7fd5520dbe2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["NB loaded in local\n"]}]},{"cell_type":"markdown","source":["Scoring users on humility"],"metadata":{"id":"Q2OycYj0a-Ur"}},{"cell_type":"code","source":["if skip_gated_model == False:\n","  %pip install outlines\n","  import json\n","  import pandas as pd\n","  import torch\n","  import outlines\n","  import random\n","\n","\n","  #config\n","  comment_limit = 5\n","  random.seed(totally_random)\n","\n","  #few shot examples\n","  #get random examples every time.\n","  df = pd.read_csv(data_path_val)\n","  df_sorted = df.sort_values(by='Humility').reset_index(drop=True)\n","  low_humility_start_idx = 0\n","  medium_humility_start_idx = df_sorted[df_sorted['Humility'] > 33].index[0]\n","  high_humility_start_idx = df_sorted[df_sorted['Humility'] > 66].index[0]\n","  def get_random_examples(df_sorted):\n","    few_shot_examples = []\n","    rand_low_idx = random.choice(range(low_humility_start_idx,medium_humility_start_idx))\n","    rand_med_idx = random.choice(range(medium_humility_start_idx,high_humility_start_idx))\n","    rand_hi_idx = random.choice(range(high_humility_start_idx,len(df_sorted)))\n","    selected_idx = [rand_low_idx,rand_med_idx,rand_hi_idx]\n","    selected_rows = df_sorted.iloc[selected_idx]\n","    for index, row in selected_rows.iterrows():\n","      value_tuple = ([row['Q1'], row['Q2'], row['Q3']],row['Humility']/100)\n","      few_shot_examples.append(value_tuple)\n","    random.shuffle(few_shot_examples)\n","    return few_shot_examples\n","\n","  #model\n","  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","  print(f'device: {device}')\n","  model_name = \"meta-llama/Llama-3.2-3B-Instruct\"\n","  model = outlines.models.transformers(model_name, device=device)\n","  pattern = r'0\\.\\d{2}|1\\.00'\n","  generator = outlines.generate.regex(model, pattern)\n","\n","  #prompt\n","  prompt = f\"\"\"\n","    You are an expert in personality psychology. I want you to rate the humility of a person based on their comments. Begin your answer with the score (a number between 0.00 and 1.00).\n","    Indicators of humility are:\n","    Sincerity\n","    Fairness\n","    Greed-Avoidance\n","    Modesty\n","\n","    Here are some examples of accurate scores:\n","    \"\"\"\n","\n","\n","  #execute\n","  print('Scoring authors based on 5 random comments (seed=42)...')\n","\n","  for i, author in enumerate(authors):\n","    random.shuffle(author['comments'])\n","    working_comments = [comment for comment in author['comments']][:comment_limit]\n","\n","    few_shot_examples = get_random_examples(df_sorted)\n","    ex_text1 = few_shot_examples[0][0]\n","    ex_hum1 = few_shot_examples[0][1]\n","    ex_text2 = few_shot_examples[1][0]\n","    ex_hum2 = few_shot_examples[1][1]\n","    ex_text3 = few_shot_examples[2][0]\n","    ex_hum3 = few_shot_examples[2][1]\n","    end_prompt = f'''\n","    Example 1:\n","    Comments:{ex_text1}\n","    Humility:{ex_hum1}\n","    Example 2:\n","    Comments:{ex_text2}\n","    Humility:{ex_hum2}\n","    Example 3:\n","    Comments:{ex_text3}\n","    Humility:{ex_hum3}\n","\n","    What level of humility does the following person have?\n","    Comments:{working_comments}\n","    Humility:\n","    '''\n","    final_prompt = prompt + end_prompt\n","    if i == 0:\n","      print(f'Example final prompt:\\n{final_prompt}')\n","    answer = generator(final_prompt, max_tokens=4)\n","    print(f'{i}/{len(authors)}:{answer}')\n","    author['labels']['humility'] = float(answer)\n","else:\n","  print('Skipping model and using local data')\n","  use_hum_list = True\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["df942953e582463795f2add818b78b66","d8a00e85ccd645f8bd12457db81c0d43","7aa60d7cfbf54872b72c4b0bedf1b3f2","1371e57b49334fafa19c60b3af49ac87","9a2f69acff224a599da9641b58309ddd","4c72890d7f9d4d3b83f5d724f8da56a6","34e37c606a4d41fcb83667e587a5d6a3","af2373f62b6b4e4285270918f5336dd1","666487c81a9343f591690be35208dbca","68faeff657564b5792c05870a612ec44","7a0386db4b4c4ae983a908a195be0cb4"]},"id":"VUlNv63Majjq","outputId":"5aeb19d7-3cdc-4f50-8df8-7116729091bd","executionInfo":{"status":"ok","timestamp":1747698450910,"user_tz":-120,"elapsed":6058121,"user":{"displayName":"Geran De Rijk","userId":"14984877830666793525"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: outlines in /usr/local/lib/python3.11/dist-packages (0.2.3)\n","Requirement already satisfied: interegular in /usr/local/lib/python3.11/dist-packages (from outlines) (0.3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from outlines) (3.1.6)\n","Requirement already satisfied: lark in /usr/local/lib/python3.11/dist-packages (from outlines) (1.2.2)\n","Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.11/dist-packages (from outlines) (1.6.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from outlines) (2.0.2)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from outlines) (3.1.1)\n","Requirement already satisfied: diskcache in /usr/local/lib/python3.11/dist-packages (from outlines) (5.6.3)\n","Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from outlines) (2.11.4)\n","Requirement already satisfied: referencing in /usr/local/lib/python3.11/dist-packages (from outlines) (0.36.2)\n","Requirement already satisfied: jsonschema in /usr/local/lib/python3.11/dist-packages (from outlines) (4.23.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from outlines) (2.32.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from outlines) (4.67.1)\n","Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from outlines) (4.13.2)\n","Requirement already satisfied: iso3166 in /usr/local/lib/python3.11/dist-packages (from outlines) (2.1.1)\n","Requirement already satisfied: airportsdata in /usr/local/lib/python3.11/dist-packages (from outlines) (20250224)\n","Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from outlines) (2.6.0+cu124)\n","Requirement already satisfied: outlines_core==0.1.26 in /usr/local/lib/python3.11/dist-packages (from outlines) (0.1.26)\n","Requirement already satisfied: genson in /usr/local/lib/python3.11/dist-packages (from outlines) (1.3.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->outlines) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->outlines) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->outlines) (0.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->outlines) (3.0.2)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema->outlines) (25.3.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema->outlines) (2025.4.1)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema->outlines) (0.24.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->outlines) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->outlines) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->outlines) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->outlines) (2025.4.26)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->outlines) (3.18.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->outlines) (3.4.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->outlines) (2025.3.2)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->outlines) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->outlines) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->outlines) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->outlines) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->outlines) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->outlines) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->outlines) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->outlines) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->outlines) (12.3.1.170)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->outlines) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->outlines) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->outlines) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->outlines) (12.4.127)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->outlines) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->outlines) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->outlines) (1.3.0)\n","device: cuda\n"]},{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df942953e582463795f2add818b78b66"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Base prompt:\n","\n","    You are an expert in personality psychology. I want you to rate the humility of a person based on their comments. Begin your answer with the score (a number between 0.00 and 1.00).\n","    Indicators of humility are:\n","    Sincerity\n","    Fairness\n","    Greed-Avoidance\n","    Modesty\n","\n","    Here are some examples of accurate scores:\n","    \n","Scoring authors based on 5 random comments (seed=42)...\n","Example final prompt:\n","\n","    You are an expert in personality psychology. I want you to rate the humility of a person based on their comments. Begin your answer with the score (a number between 0.00 and 1.00).\n","    Indicators of humility are:\n","    Sincerity\n","    Fairness\n","    Greed-Avoidance\n","    Modesty\n","\n","    Here are some examples of accurate scores:\n","    \n","    Example 1:\n","    Comments:['Latin from the books of the Laws of England, which taken along with the context, means, that of all whales captured by anybody on the coast of that land, the King, as Honorary Grand Harpooneer, must have the head, and the Queen be respectfully presented with the tail. A division which, in the whale, is much like halving an apple; there is no intermediate remainder. Now as this law, under a modified form, is to this day in force in England; and as it offers in various respects a strange anomaly touching the general law of Fast and Loose-Fish, it is here treated of in a separate chapter, on the same courteous principle that prompts the English railways to be at the expense of a separate car, specially reserved for the accommodation of royalty. In the first place, in curious proof of the fact that the above-mentioned law is still in force, I proceed to lay before you a circumstance that happened within the last two years.', 'It seems that some honest mariners of Dover, or Sandwich, or some one of the Cinque Ports, had after a hard chase succeeded in killing and beaching a fine whale which they had originally descried afar off from the shore. Now the Cinque Ports are partially or somehow under the jurisdiction of a sort of policeman or beadle, called a Lord Warden. Holding the office directly from the crown, I believe, all the royal emoluments incident to the Cinque Port territories become by assignment his. By some writers this office is called a sinecure. But not so. Because the Lord Warden is busily employed at times in fobbing his perquisites; which are his chiefly by virtue of that same fobbing of them.', 'Now when these poor sun-burnt mariners, bare-footed, and with their trowsers rolled high up on their eely legs, had wearily hauled their fat fish high and dry, promising themselves a good £150 from the precious oil and bone; and in fantasy sipping rare tea with their wives, and good ale with their cronies, upon the strength of their respective shares; up steps a very learned and most Christian and charitable gentleman, with a copy of Blackstone under his arm; and laying it upon the whale\\'s head, he says—\"Hands off! this fish, my masters, is a Fast-Fish. I seize it as the Lord Warden\\'s.\" Upon this the poor mariners in their respectful consternation—so truly English—knowing not what to say, fall to vigorously scratching their heads all round; meanwhile ruefully glancing from the whale to the stranger. But that did in nowise mend the matter, or at all soften the hard heart of the learned gentleman with the copy of Blackstone. At length one of them, after long scratching about for his ideas, made bold to speak,']\n","    Humility:0.43\n","    Example 2:\n","    Comments:[\"To preface this story I'll first share a bit of context: For my bachelors degree I studied abroad in China for about 11 months, in combination with doing my internship for my masters there as well. When we first arrived it quickly became clear my Chinese was slightly stinted and more or less insufficient to survive the administrative horrors of moving across continents. The first arduous task was to open a bank account. None of the admin personnel at our host university knew English but we quickly figured out we would need to first apply for a Chinese phone number. I decided to ask other international students for help and managed to find a Russian girl who spoke some English who also didn't know how to solve our problem. Together we ended up searching for a Chinese teacher who spoke Russian so we could ask the student to translate our questions to her. All of us ended up going to the bank together and succesfully opened a bank account despite the language barriers.\", \"This story is quite a silly one, but i feel it showcases some of my irritating character flaws, so I'll share it anyway. I work part-time as a waiter in a wedding venue. It's hard work and I'm often there until fairly late at night. One such night I was truly exhausted and had an early morning class the day after. Most of our closing tasks had been done and it was finally almost time to go home when I dropped a full rack of glasses in my fatigued rush to get home quickly.  Had I taken my time to see it through patiently OR decided not tot spread myself as thin this mistake could've been easily avoided.\", \"I was on the board as secretary (and later HR officer) of a student association for quite some time. We organised multiple activities every month with a relatively minor budget, which was quite stressful at times. The largest issues we encountered, however, were interpersonal ones: many of our team truly struggled to work together because of everything from useless drama to clashing personalities. It often irritated me greatly that others lacked the maturity to put aside personal differences to work together as a team, but then realised irritation is not the best headspace to approach that from. I quickly learned an understanding an compassionate attitude, while way more effort, gets better results. It has always and probably will always be easier for me to work together with people with similar mindsets to me, but nowadays I'm quite good at feigning whatever I need to get a decent end result. In the end we had many succesful activities and our association truly made a lot of connections possible between members.\"]\n","    Humility:0.11\n","    Example 3:\n","    Comments:['I work a student job at a catering company. One time, unexpectedly, my boss was absent, so I had to take on his leading role of managing the kitchen and communicating with whoever commissioned the reception. This was obviously too much for a single person to handle, but in the end I managed to make everything run smoothly by focusing on efficiency. Instead of running errands for everyone, I told the commissioner and the kitchen staff to come to me with every need or problem, which made it easier to keep track of all the timings. After hearing about this, my boss now applies the same strategy.', 'As a hobby I play a competitive card game. Usually I am well prepared for tournaments, as was the same for my first ever big tournament. The night before, I panicked, not believing in the deck I chose and started neurotically messaging all my friends for advice. I ended up making a bunch of changes to my deck, which were suboptimal changes to begin with, which resulted in me not knowing the deck I was piloting, and making unfortunate mistakes throughout the entire day. All my prep was thrown into the water the night before just because of my mental state. I learned to trust my own judgements and to be confident in my abilities.', \"Building on my answer to question 1, I now frequently have to take on a more managerial role at my student job. One time, I was put in charge of a group of fellow students for a big event. I became focused on figuring out everyone's strengths and needs, to optimally assign each of them a role. I tried messaging each one beforehand, which surprisingly didn't turn out to be a success. I barely got any replies. So, the night before, I busted out my notepad to make a comprehensive list of everyone's strengths, weaknesses, and possible pairings. The next day, I simply decided to bluntly assign everyone a role, based on my notes, which worked out a lot better. The day ended up going well, and I figured out that people perform better if they just get told what to do or where to be in the catering industry.\"]\n","    Humility:0.83\n","\n","    What level of humility does the following person have?\n","    Comments:[\"Your first and second question is the same question. I'll try to make it more incisive for you because you don't articulate what you want to know. Do I think people who cooperate also compete? Yeah, sure, obviously, in a separate way people who play chess, or style themselves in order to be attractive, merely agree that there is a game and the game has rules. Fine. I don't think they cooperate in terms of winning the game because if I know, especially because you've told me, what you're planning that is self-defeating. It's mere agreement to a definition, it's not the point of the game, the point is to win. My approach to life isn't centered on men or maleness (that's what androcentric means), I am a man so I have to focus on myself but I care about things most people care about regardless of owning a penis. Hard to tell if you're asking me if I'm being self-centered or not because I don't know how I could be focused on men as an 'approach to life'. Mining is androcentric because that industry relies on men doing the majority of the labor if that makes the word usage clearer. \", \"I suggest the future. You aren't going back into your past any time soon and the present authoring can be daunting as it has you delineate what is and is not virtue and vice. The future is where you should be aiming. Start there so you know what you value and why you want what you value. The past authoring is very taxing. I had to do it over months and I'm only 30 as of February. The future authoring is also taxing but not in the same way and it's immediately beneficial. Do them however you feel but the future is where you're going to be first. Right... there it goes... here it is... oh fuck there it went. [See; Carlin, George]\", \"I have two friends. I alienate everyone, eventually, by being a dick and too demanding. Things that should bother me never do which include my own shameful, dangerous, and immoral behaviour. I have no natural happiness or energy (not that I care about my own happiness because I don't) and people that do have any enthusiasm bother the christing fuck out of me since, to me, they appear to be too stupid to notice important details. If I am not in a competition I am not intrinsically interested in what's happening such that cooperation of any sort appears to be gynocentric hippy cuckfoolery populated by seventeen-year-old girls meeting in a walk-in closet to discuss hair. I am not lucky, I make it work. \", 'I am smarter than you and will work you into dust. Stand in my way I dare each and every one of you.- Agreeableness: 0%- Compassion: 4%- Politeness: 0%- Conscientiousness: 96%- Industriousness: 97%- Orderliness: 84%- Extraversion: 60%- Enthusiasm: 25%- Assertiveness: 85%- Neuroticism: 1%- Withdrawal: 2%- Volatility: 1%- Openness to Experience: 99%- Intellect: 97%- Openness: 97%', 'Yeah I wouldnt want to deal with someone like me either. Move along. ��']\n","    Humility:\n","    \n","0/1496:0.02\n","1/1496:0.05\n","2/1496:0.00\n","3/1496:0.45\n","4/1496:0.00\n","5/1496:0.00\n","6/1496:0.00\n","7/1496:1.00\n","8/1496:0.09\n","9/1496:0.01\n","10/1496:0.10\n","11/1496:0.36\n","12/1496:0.01\n","13/1496:0.00\n","14/1496:0.02\n","15/1496:0.11\n","16/1496:0.00\n","17/1496:0.00\n","18/1496:0.00\n","19/1496:1.00\n","20/1496:0.96\n","21/1496:0.55\n","22/1496:0.01\n","23/1496:0.00\n","24/1496:0.00\n","25/1496:0.12\n","26/1496:0.44\n","27/1496:0.18\n","28/1496:0.01\n","29/1496:0.57\n","30/1496:0.45\n","31/1496:0.99\n","32/1496:0.00\n","33/1496:0.43\n","34/1496:0.10\n","35/1496:0.58\n","36/1496:0.88\n","37/1496:0.01\n","38/1496:0.33\n","39/1496:0.23\n","40/1496:1.00\n","41/1496:1.00\n","42/1496:0.01\n","43/1496:0.21\n","44/1496:0.09\n","45/1496:0.68\n","46/1496:0.01\n","47/1496:0.36\n","48/1496:0.10\n","49/1496:1.00\n","50/1496:0.00\n","51/1496:0.00\n","52/1496:1.00\n","53/1496:0.03\n","54/1496:0.77\n","55/1496:0.05\n","56/1496:0.05\n","57/1496:0.37\n","58/1496:0.00\n","59/1496:0.09\n","60/1496:0.39\n","61/1496:0.09\n","62/1496:0.00\n","63/1496:0.56\n","64/1496:0.24\n","65/1496:0.00\n","66/1496:0.35\n","67/1496:0.00\n","68/1496:1.00\n","69/1496:0.10\n","70/1496:0.07\n","71/1496:0.03\n","72/1496:0.20\n","73/1496:0.19\n","74/1496:0.17\n","75/1496:0.80\n","76/1496:0.19\n","77/1496:0.14\n","78/1496:0.00\n","79/1496:0.06\n","80/1496:0.10\n","81/1496:0.15\n","82/1496:0.00\n","83/1496:0.01\n","84/1496:0.07\n","85/1496:0.00\n","86/1496:0.00\n","87/1496:0.13\n","88/1496:0.03\n","89/1496:0.00\n","90/1496:0.00\n","91/1496:0.16\n","92/1496:0.00\n","93/1496:1.00\n","94/1496:1.00\n","95/1496:0.11\n","96/1496:0.02\n","97/1496:0.61\n","98/1496:0.00\n","99/1496:0.06\n","100/1496:0.99\n","101/1496:0.50\n","102/1496:0.42\n","103/1496:0.07\n","104/1496:0.04\n","105/1496:0.02\n","106/1496:0.19\n","107/1496:0.00\n","108/1496:0.32\n","109/1496:0.51\n","110/1496:0.05\n","111/1496:0.45\n","112/1496:0.28\n","113/1496:0.07\n","114/1496:0.00\n","115/1496:1.00\n","116/1496:0.08\n","117/1496:0.57\n","118/1496:0.00\n","119/1496:0.01\n","120/1496:0.08\n","121/1496:0.34\n","122/1496:0.26\n","123/1496:0.12\n","124/1496:0.03\n","125/1496:0.45\n","126/1496:0.00\n","127/1496:0.00\n","128/1496:0.06\n","129/1496:0.01\n","130/1496:0.28\n","131/1496:0.08\n","132/1496:1.00\n","133/1496:0.00\n","134/1496:1.00\n","135/1496:0.00\n","136/1496:0.00\n","137/1496:0.23\n","138/1496:0.00\n","139/1496:0.07\n","140/1496:0.07\n","141/1496:0.00\n","142/1496:0.00\n","143/1496:0.45\n","144/1496:0.21\n","145/1496:0.24\n","146/1496:0.74\n","147/1496:0.05\n","148/1496:1.00\n","149/1496:0.31\n","150/1496:0.12\n","151/1496:0.04\n","152/1496:0.11\n","153/1496:0.21\n","154/1496:0.01\n","155/1496:0.13\n","156/1496:0.50\n","157/1496:0.00\n","158/1496:0.05\n","159/1496:0.00\n","160/1496:0.56\n","161/1496:1.00\n","162/1496:0.04\n","163/1496:1.00\n","164/1496:0.99\n","165/1496:0.47\n","166/1496:1.00\n","167/1496:0.00\n","168/1496:0.00\n","169/1496:0.85\n","170/1496:1.00\n","171/1496:0.07\n","172/1496:0.00\n","173/1496:0.26\n","174/1496:0.05\n","175/1496:0.00\n","176/1496:0.04\n","177/1496:0.81\n","178/1496:1.00\n","179/1496:0.19\n","180/1496:0.03\n","181/1496:0.84\n","182/1496:0.35\n","183/1496:0.31\n","184/1496:0.51\n","185/1496:0.01\n","186/1496:0.07\n","187/1496:0.45\n","188/1496:0.29\n","189/1496:0.09\n","190/1496:0.12\n","191/1496:0.03\n","192/1496:0.00\n","193/1496:0.01\n","194/1496:0.12\n","195/1496:0.00\n","196/1496:0.08\n","197/1496:0.00\n","198/1496:0.71\n","199/1496:0.46\n","200/1496:0.98\n","201/1496:0.13\n","202/1496:0.18\n","203/1496:0.28\n","204/1496:0.07\n","205/1496:0.33\n","206/1496:0.51\n","207/1496:0.00\n","208/1496:0.15\n","209/1496:0.89\n","210/1496:0.00\n","211/1496:0.21\n","212/1496:0.34\n","213/1496:0.92\n","214/1496:0.84\n","215/1496:0.00\n","216/1496:0.36\n","217/1496:0.00\n","218/1496:0.05\n","219/1496:0.00\n","220/1496:1.00\n","221/1496:0.07\n","222/1496:0.00\n","223/1496:0.00\n","224/1496:0.00\n","225/1496:0.40\n","226/1496:0.11\n","227/1496:0.03\n","228/1496:0.06\n","229/1496:0.97\n","230/1496:0.01\n","231/1496:0.22\n","232/1496:0.00\n","233/1496:0.09\n","234/1496:0.78\n","235/1496:0.15\n","236/1496:0.00\n","237/1496:0.54\n","238/1496:0.05\n","239/1496:0.14\n","240/1496:0.58\n","241/1496:0.00\n","242/1496:0.00\n","243/1496:0.31\n","244/1496:1.00\n","245/1496:0.29\n","246/1496:0.02\n","247/1496:0.99\n","248/1496:0.42\n","249/1496:0.00\n","250/1496:0.05\n","251/1496:0.00\n","252/1496:0.08\n","253/1496:0.00\n","254/1496:0.07\n","255/1496:0.86\n","256/1496:0.00\n","257/1496:0.05\n","258/1496:0.00\n","259/1496:0.78\n","260/1496:0.65\n","261/1496:0.01\n","262/1496:0.01\n","263/1496:0.49\n","264/1496:0.26\n","265/1496:0.01\n","266/1496:0.40\n","267/1496:1.00\n","268/1496:0.05\n","269/1496:0.14\n","270/1496:0.00\n","271/1496:0.75\n","272/1496:0.05\n","273/1496:0.01\n","274/1496:0.05\n","275/1496:0.01\n","276/1496:0.92\n","277/1496:0.04\n","278/1496:0.01\n","279/1496:0.00\n","280/1496:0.07\n","281/1496:0.22\n","282/1496:0.05\n","283/1496:0.03\n","284/1496:0.12\n","285/1496:0.00\n","286/1496:0.00\n","287/1496:0.00\n","288/1496:0.40\n","289/1496:0.39\n","290/1496:0.08\n","291/1496:1.00\n","292/1496:0.01\n","293/1496:0.00\n","294/1496:0.33\n","295/1496:0.47\n","296/1496:0.00\n","297/1496:0.05\n","298/1496:0.00\n","299/1496:0.08\n","300/1496:0.00\n","301/1496:0.16\n","302/1496:0.00\n","303/1496:0.07\n","304/1496:0.00\n","305/1496:0.17\n","306/1496:1.00\n","307/1496:1.00\n","308/1496:0.06\n","309/1496:0.00\n","310/1496:0.19\n","311/1496:0.15\n","312/1496:0.87\n","313/1496:0.06\n","314/1496:0.00\n","315/1496:0.00\n","316/1496:0.05\n","317/1496:0.00\n","318/1496:0.43\n","319/1496:0.27\n","320/1496:0.48\n","321/1496:1.00\n","322/1496:1.00\n","323/1496:0.46\n","324/1496:0.00\n","325/1496:0.01\n","326/1496:0.01\n","327/1496:0.69\n","328/1496:0.00\n","329/1496:0.20\n","330/1496:0.86\n","331/1496:0.01\n","332/1496:0.00\n","333/1496:0.00\n","334/1496:0.80\n","335/1496:1.00\n","336/1496:0.75\n","337/1496:0.00\n","338/1496:0.03\n","339/1496:0.04\n","340/1496:0.13\n","341/1496:0.14\n","342/1496:0.73\n","343/1496:0.00\n","344/1496:0.00\n","345/1496:0.62\n","346/1496:0.32\n","347/1496:0.42\n","348/1496:0.13\n","349/1496:0.00\n","350/1496:0.00\n","351/1496:0.12\n","352/1496:0.08\n","353/1496:1.00\n","354/1496:0.41\n","355/1496:0.00\n","356/1496:0.98\n","357/1496:0.46\n","358/1496:1.00\n","359/1496:1.00\n","360/1496:0.02\n","361/1496:1.00\n","362/1496:0.00\n","363/1496:0.43\n","364/1496:0.90\n","365/1496:0.11\n","366/1496:0.32\n","367/1496:0.32\n","368/1496:0.19\n","369/1496:0.00\n","370/1496:0.00\n","371/1496:0.32\n","372/1496:0.01\n","373/1496:0.00\n","374/1496:0.00\n","375/1496:0.13\n","376/1496:0.05\n","377/1496:0.00\n","378/1496:0.00\n","379/1496:0.06\n","380/1496:0.00\n","381/1496:0.01\n","382/1496:0.67\n","383/1496:0.02\n","384/1496:0.57\n","385/1496:0.78\n","386/1496:0.00\n","387/1496:0.90\n","388/1496:0.00\n","389/1496:0.01\n","390/1496:0.00\n","391/1496:0.05\n","392/1496:0.89\n","393/1496:0.16\n","394/1496:0.96\n","395/1496:0.35\n","396/1496:0.02\n","397/1496:0.00\n","398/1496:0.04\n","399/1496:0.00\n","400/1496:0.04\n","401/1496:0.08\n","402/1496:0.88\n","403/1496:1.00\n","404/1496:1.00\n","405/1496:1.00\n","406/1496:0.51\n","407/1496:0.10\n","408/1496:1.00\n","409/1496:0.00\n","410/1496:0.67\n","411/1496:0.00\n","412/1496:0.16\n","413/1496:0.01\n","414/1496:0.03\n","415/1496:0.10\n","416/1496:0.49\n","417/1496:0.05\n","418/1496:0.11\n","419/1496:0.00\n","420/1496:0.00\n","421/1496:0.01\n","422/1496:0.00\n","423/1496:0.43\n","424/1496:0.00\n","425/1496:0.75\n","426/1496:0.41\n","427/1496:0.06\n","428/1496:0.02\n","429/1496:0.66\n","430/1496:0.86\n","431/1496:0.05\n","432/1496:0.07\n","433/1496:0.45\n","434/1496:0.98\n","435/1496:0.00\n","436/1496:0.14\n","437/1496:0.00\n","438/1496:0.00\n","439/1496:0.40\n","440/1496:0.08\n","441/1496:0.04\n","442/1496:0.78\n","443/1496:0.00\n","444/1496:0.65\n","445/1496:0.11\n","446/1496:0.96\n","447/1496:0.01\n","448/1496:0.64\n","449/1496:0.96\n","450/1496:0.00\n","451/1496:0.00\n","452/1496:0.21\n","453/1496:0.05\n","454/1496:0.28\n","455/1496:1.00\n","456/1496:0.00\n","457/1496:0.24\n","458/1496:0.05\n","459/1496:1.00\n","460/1496:0.00\n","461/1496:0.04\n","462/1496:1.00\n","463/1496:0.01\n","464/1496:0.56\n","465/1496:0.00\n","466/1496:0.00\n","467/1496:0.63\n","468/1496:0.00\n","469/1496:0.07\n","470/1496:0.21\n","471/1496:0.16\n","472/1496:0.00\n","473/1496:0.00\n","474/1496:0.00\n","475/1496:0.15\n","476/1496:0.03\n","477/1496:0.01\n","478/1496:0.00\n","479/1496:0.50\n","480/1496:0.08\n","481/1496:0.00\n","482/1496:0.12\n","483/1496:0.00\n","484/1496:0.05\n","485/1496:0.20\n","486/1496:0.00\n","487/1496:0.14\n","488/1496:0.14\n","489/1496:0.00\n","490/1496:0.40\n","491/1496:0.01\n","492/1496:0.71\n","493/1496:0.00\n","494/1496:0.02\n","495/1496:0.00\n","496/1496:0.00\n","497/1496:0.00\n","498/1496:0.00\n","499/1496:0.01\n","500/1496:0.15\n","501/1496:0.16\n","502/1496:0.06\n","503/1496:0.00\n","504/1496:0.59\n","505/1496:1.00\n","506/1496:0.87\n","507/1496:0.05\n","508/1496:0.00\n","509/1496:0.09\n","510/1496:0.10\n","511/1496:0.18\n","512/1496:0.01\n","513/1496:0.51\n","514/1496:0.09\n","515/1496:0.38\n","516/1496:0.50\n","517/1496:0.05\n","518/1496:0.45\n","519/1496:0.80\n","520/1496:0.07\n","521/1496:0.00\n","522/1496:0.48\n","523/1496:1.00\n","524/1496:0.46\n","525/1496:0.72\n","526/1496:1.00\n","527/1496:0.01\n","528/1496:0.14\n","529/1496:0.00\n","530/1496:0.23\n","531/1496:0.13\n","532/1496:0.11\n","533/1496:0.85\n","534/1496:1.00\n","535/1496:0.99\n","536/1496:0.00\n","537/1496:0.04\n","538/1496:1.00\n","539/1496:0.40\n","540/1496:0.00\n","541/1496:0.00\n","542/1496:0.54\n","543/1496:0.00\n","544/1496:0.00\n","545/1496:0.12\n","546/1496:0.25\n","547/1496:0.00\n","548/1496:0.72\n","549/1496:1.00\n","550/1496:0.00\n","551/1496:0.01\n","552/1496:0.82\n","553/1496:0.01\n","554/1496:0.07\n","555/1496:0.00\n","556/1496:0.00\n","557/1496:0.00\n","558/1496:0.15\n","559/1496:0.00\n","560/1496:0.07\n","561/1496:0.01\n","562/1496:0.65\n","563/1496:0.85\n","564/1496:0.08\n","565/1496:0.09\n","566/1496:0.15\n","567/1496:0.96\n","568/1496:1.00\n","569/1496:0.56\n","570/1496:0.46\n","571/1496:0.95\n","572/1496:0.42\n","573/1496:0.01\n","574/1496:0.32\n","575/1496:0.00\n","576/1496:0.00\n","577/1496:0.41\n","578/1496:0.05\n","579/1496:0.89\n","580/1496:0.08\n","581/1496:0.06\n","582/1496:0.23\n","583/1496:0.35\n","584/1496:0.05\n","585/1496:0.16\n","586/1496:0.00\n","587/1496:0.02\n","588/1496:0.04\n","589/1496:0.00\n","590/1496:0.57\n","591/1496:0.15\n","592/1496:0.05\n","593/1496:0.00\n","594/1496:0.00\n","595/1496:0.07\n","596/1496:0.99\n","597/1496:0.00\n","598/1496:0.07\n","599/1496:0.31\n","600/1496:0.73\n","601/1496:0.92\n","602/1496:0.35\n","603/1496:0.24\n","604/1496:0.45\n","605/1496:0.08\n","606/1496:0.09\n","607/1496:0.05\n","608/1496:1.00\n","609/1496:0.00\n","610/1496:1.00\n","611/1496:0.00\n","612/1496:0.42\n","613/1496:0.00\n","614/1496:0.99\n","615/1496:0.57\n","616/1496:0.23\n","617/1496:0.00\n","618/1496:0.31\n","619/1496:0.88\n","620/1496:0.00\n","621/1496:0.09\n","622/1496:0.96\n","623/1496:0.00\n","624/1496:0.80\n","625/1496:0.03\n","626/1496:0.00\n","627/1496:0.00\n","628/1496:0.07\n","629/1496:0.37\n","630/1496:0.00\n","631/1496:0.05\n","632/1496:0.00\n","633/1496:0.00\n","634/1496:0.00\n","635/1496:0.36\n","636/1496:0.01\n","637/1496:1.00\n","638/1496:0.69\n","639/1496:0.98\n","640/1496:0.15\n","641/1496:0.85\n","642/1496:0.11\n","643/1496:0.00\n","644/1496:0.91\n","645/1496:0.99\n","646/1496:1.00\n","647/1496:0.15\n","648/1496:0.27\n","649/1496:0.00\n","650/1496:0.00\n","651/1496:0.00\n","652/1496:0.00\n","653/1496:0.05\n","654/1496:0.37\n","655/1496:0.00\n","656/1496:0.15\n","657/1496:0.03\n","658/1496:0.00\n","659/1496:0.27\n","660/1496:0.03\n","661/1496:0.02\n","662/1496:0.01\n","663/1496:0.88\n","664/1496:0.29\n","665/1496:0.04\n","666/1496:0.03\n","667/1496:0.04\n","668/1496:0.08\n","669/1496:0.00\n","670/1496:0.02\n","671/1496:0.59\n","672/1496:0.00\n","673/1496:0.04\n","674/1496:0.75\n","675/1496:0.01\n","676/1496:0.09\n","677/1496:0.75\n","678/1496:0.03\n","679/1496:0.05\n","680/1496:0.26\n","681/1496:0.03\n","682/1496:0.45\n","683/1496:0.00\n","684/1496:0.03\n","685/1496:0.10\n","686/1496:0.02\n","687/1496:0.00\n","688/1496:0.71\n","689/1496:0.58\n","690/1496:0.00\n","691/1496:0.00\n","692/1496:0.00\n","693/1496:0.00\n","694/1496:0.00\n","695/1496:0.05\n","696/1496:0.05\n","697/1496:0.51\n","698/1496:0.03\n","699/1496:0.87\n","700/1496:1.00\n","701/1496:0.00\n","702/1496:0.28\n","703/1496:0.00\n","704/1496:0.05\n","705/1496:0.18\n","706/1496:0.28\n","707/1496:0.02\n","708/1496:0.00\n","709/1496:0.25\n","710/1496:0.06\n","711/1496:0.03\n","712/1496:0.13\n","713/1496:0.01\n","714/1496:0.22\n","715/1496:0.08\n","716/1496:0.89\n","717/1496:0.05\n","718/1496:0.01\n","719/1496:0.00\n","720/1496:0.64\n","721/1496:0.36\n","722/1496:0.82\n","723/1496:0.55\n","724/1496:0.99\n","725/1496:0.05\n","726/1496:0.05\n","727/1496:0.05\n","728/1496:0.00\n","729/1496:0.56\n","730/1496:0.00\n","731/1496:0.79\n","732/1496:0.09\n","733/1496:0.00\n","734/1496:0.00\n","735/1496:0.17\n","736/1496:0.04\n","737/1496:0.01\n","738/1496:0.00\n","739/1496:0.69\n","740/1496:0.00\n","741/1496:0.23\n","742/1496:0.10\n","743/1496:0.01\n","744/1496:0.05\n","745/1496:0.07\n","746/1496:0.06\n","747/1496:1.00\n","748/1496:0.13\n","749/1496:0.15\n","750/1496:0.03\n","751/1496:0.79\n","752/1496:1.00\n","753/1496:0.29\n","754/1496:0.07\n","755/1496:0.03\n","756/1496:0.00\n","757/1496:0.57\n","758/1496:0.00\n","759/1496:0.15\n","760/1496:1.00\n","761/1496:0.00\n","762/1496:0.45\n","763/1496:0.10\n","764/1496:0.10\n","765/1496:0.55\n","766/1496:0.06\n","767/1496:0.00\n","768/1496:0.19\n","769/1496:0.00\n","770/1496:0.00\n","771/1496:0.00\n","772/1496:0.56\n","773/1496:0.00\n","774/1496:0.45\n","775/1496:1.00\n","776/1496:0.14\n","777/1496:0.00\n","778/1496:0.80\n","779/1496:0.08\n","780/1496:1.00\n","781/1496:0.15\n","782/1496:0.08\n","783/1496:0.61\n","784/1496:0.63\n","785/1496:0.05\n","786/1496:0.08\n","787/1496:0.07\n","788/1496:0.08\n","789/1496:0.00\n","790/1496:0.00\n","791/1496:0.01\n","792/1496:0.07\n","793/1496:0.79\n","794/1496:0.75\n","795/1496:0.04\n","796/1496:0.00\n","797/1496:0.00\n","798/1496:0.00\n","799/1496:0.01\n","800/1496:0.94\n","801/1496:0.00\n","802/1496:0.76\n","803/1496:0.00\n","804/1496:0.01\n","805/1496:0.05\n","806/1496:0.96\n","807/1496:0.37\n","808/1496:0.14\n","809/1496:0.00\n","810/1496:0.39\n","811/1496:0.87\n","812/1496:0.00\n","813/1496:0.00\n","814/1496:0.79\n","815/1496:0.74\n","816/1496:0.00\n","817/1496:0.49\n","818/1496:0.10\n","819/1496:0.12\n","820/1496:0.00\n","821/1496:0.00\n","822/1496:0.07\n","823/1496:1.00\n","824/1496:0.88\n","825/1496:0.05\n","826/1496:0.00\n","827/1496:0.25\n","828/1496:0.02\n","829/1496:0.83\n","830/1496:1.00\n","831/1496:0.00\n","832/1496:0.15\n","833/1496:1.00\n","834/1496:0.65\n","835/1496:1.00\n","836/1496:0.00\n","837/1496:0.00\n","838/1496:0.01\n","839/1496:0.04\n","840/1496:0.00\n","841/1496:0.00\n","842/1496:0.65\n","843/1496:0.04\n","844/1496:0.05\n","845/1496:0.04\n","846/1496:0.00\n","847/1496:0.68\n","848/1496:0.37\n","849/1496:0.01\n","850/1496:0.00\n","851/1496:0.00\n","852/1496:0.15\n","853/1496:0.00\n","854/1496:0.00\n","855/1496:0.38\n","856/1496:0.99\n","857/1496:0.81\n","858/1496:0.00\n","859/1496:0.00\n","860/1496:0.12\n","861/1496:0.07\n","862/1496:0.86\n","863/1496:0.00\n","864/1496:0.81\n","865/1496:0.12\n","866/1496:0.85\n","867/1496:0.04\n","868/1496:0.00\n","869/1496:0.40\n","870/1496:0.00\n","871/1496:0.01\n","872/1496:0.87\n","873/1496:0.02\n","874/1496:0.08\n","875/1496:0.08\n","876/1496:0.84\n","877/1496:0.00\n","878/1496:0.49\n","879/1496:0.02\n","880/1496:0.00\n","881/1496:0.00\n","882/1496:0.05\n","883/1496:0.00\n","884/1496:0.01\n","885/1496:0.01\n","886/1496:0.08\n","887/1496:0.28\n","888/1496:0.05\n","889/1496:0.08\n","890/1496:0.00\n","891/1496:0.00\n","892/1496:0.01\n","893/1496:0.01\n","894/1496:0.03\n","895/1496:1.00\n","896/1496:0.01\n","897/1496:0.20\n","898/1496:0.33\n","899/1496:0.02\n","900/1496:0.10\n","901/1496:1.00\n","902/1496:0.00\n","903/1496:0.04\n","904/1496:0.05\n","905/1496:0.00\n","906/1496:0.01\n","907/1496:0.00\n","908/1496:0.11\n","909/1496:0.06\n","910/1496:0.60\n","911/1496:0.11\n","912/1496:0.00\n","913/1496:0.00\n","914/1496:0.02\n","915/1496:0.01\n","916/1496:0.00\n","917/1496:0.03\n","918/1496:0.88\n","919/1496:0.90\n","920/1496:0.00\n","921/1496:1.00\n","922/1496:0.05\n","923/1496:1.00\n","924/1496:0.02\n","925/1496:0.00\n","926/1496:0.04\n","927/1496:0.15\n","928/1496:0.89\n","929/1496:0.29\n","930/1496:0.07\n","931/1496:0.00\n","932/1496:0.97\n","933/1496:0.00\n","934/1496:0.12\n","935/1496:0.81\n","936/1496:0.05\n","937/1496:0.00\n","938/1496:0.00\n","939/1496:0.01\n","940/1496:0.00\n","941/1496:0.20\n","942/1496:0.54\n","943/1496:0.80\n","944/1496:0.78\n","945/1496:0.01\n","946/1496:0.29\n","947/1496:0.65\n","948/1496:0.05\n","949/1496:0.98\n","950/1496:0.16\n","951/1496:0.01\n","952/1496:0.03\n","953/1496:0.00\n","954/1496:0.00\n","955/1496:0.72\n","956/1496:0.13\n","957/1496:0.64\n","958/1496:0.00\n","959/1496:1.00\n","960/1496:0.16\n","961/1496:0.18\n","962/1496:0.00\n","963/1496:0.79\n","964/1496:0.51\n","965/1496:1.00\n","966/1496:0.87\n","967/1496:0.02\n","968/1496:0.08\n","969/1496:0.05\n","970/1496:0.00\n","971/1496:0.04\n","972/1496:0.07\n","973/1496:0.53\n","974/1496:0.30\n","975/1496:0.78\n","976/1496:0.34\n","977/1496:0.00\n","978/1496:0.00\n","979/1496:0.04\n","980/1496:0.19\n","981/1496:0.00\n","982/1496:1.00\n","983/1496:0.01\n","984/1496:0.05\n","985/1496:0.00\n","986/1496:0.15\n","987/1496:0.45\n","988/1496:0.01\n","989/1496:1.00\n","990/1496:0.00\n","991/1496:0.03\n","992/1496:0.23\n","993/1496:0.61\n","994/1496:0.45\n","995/1496:0.10\n","996/1496:1.00\n","997/1496:0.01\n","998/1496:1.00\n","999/1496:0.45\n","1000/1496:0.02\n","1001/1496:0.07\n","1002/1496:0.45\n","1003/1496:0.06\n","1004/1496:0.02\n","1005/1496:0.01\n","1006/1496:1.00\n","1007/1496:0.49\n","1008/1496:0.16\n","1009/1496:0.15\n","1010/1496:0.65\n","1011/1496:0.05\n","1012/1496:0.23\n","1013/1496:0.40\n","1014/1496:0.63\n","1015/1496:0.67\n","1016/1496:0.17\n","1017/1496:0.00\n","1018/1496:0.00\n","1019/1496:0.42\n","1020/1496:0.00\n","1021/1496:0.01\n","1022/1496:0.05\n","1023/1496:0.14\n","1024/1496:0.90\n","1025/1496:0.00\n","1026/1496:0.00\n","1027/1496:0.00\n","1028/1496:0.00\n","1029/1496:1.00\n","1030/1496:0.11\n","1031/1496:0.88\n","1032/1496:0.03\n","1033/1496:0.00\n","1034/1496:0.01\n","1035/1496:0.74\n","1036/1496:0.00\n","1037/1496:0.00\n","1038/1496:1.00\n","1039/1496:0.26\n","1040/1496:0.81\n","1041/1496:0.00\n","1042/1496:0.00\n","1043/1496:0.05\n","1044/1496:0.25\n","1045/1496:0.00\n","1046/1496:0.39\n","1047/1496:0.78\n","1048/1496:0.05\n","1049/1496:0.76\n","1050/1496:0.07\n","1051/1496:0.00\n","1052/1496:0.16\n","1053/1496:0.16\n","1054/1496:0.00\n","1055/1496:0.84\n","1056/1496:1.00\n","1057/1496:0.00\n","1058/1496:0.82\n","1059/1496:0.01\n","1060/1496:0.00\n","1061/1496:0.25\n","1062/1496:0.05\n","1063/1496:0.00\n","1064/1496:0.09\n","1065/1496:0.00\n","1066/1496:0.35\n","1067/1496:0.02\n","1068/1496:0.00\n","1069/1496:0.01\n","1070/1496:0.56\n","1071/1496:0.00\n","1072/1496:0.01\n","1073/1496:0.01\n","1074/1496:0.06\n","1075/1496:0.46\n","1076/1496:0.92\n","1077/1496:0.00\n","1078/1496:0.07\n","1079/1496:0.20\n","1080/1496:0.37\n","1081/1496:0.23\n","1082/1496:0.03\n","1083/1496:0.17\n","1084/1496:0.88\n","1085/1496:0.20\n","1086/1496:0.00\n","1087/1496:0.07\n","1088/1496:0.00\n","1089/1496:0.00\n","1090/1496:0.05\n","1091/1496:0.00\n","1092/1496:0.05\n","1093/1496:0.15\n","1094/1496:0.00\n","1095/1496:0.00\n","1096/1496:0.05\n","1097/1496:0.05\n","1098/1496:0.00\n","1099/1496:0.00\n","1100/1496:0.64\n","1101/1496:0.58\n","1102/1496:0.05\n","1103/1496:0.05\n","1104/1496:0.00\n","1105/1496:0.10\n","1106/1496:0.09\n","1107/1496:0.00\n","1108/1496:0.01\n","1109/1496:0.00\n","1110/1496:0.20\n","1111/1496:0.05\n","1112/1496:0.21\n","1113/1496:0.01\n","1114/1496:0.00\n","1115/1496:0.05\n","1116/1496:0.00\n","1117/1496:0.27\n","1118/1496:0.05\n","1119/1496:0.88\n","1120/1496:0.00\n","1121/1496:0.60\n","1122/1496:0.28\n","1123/1496:0.06\n","1124/1496:0.39\n","1125/1496:0.08\n","1126/1496:0.01\n","1127/1496:0.03\n","1128/1496:0.49\n","1129/1496:0.00\n","1130/1496:0.02\n","1131/1496:0.00\n","1132/1496:0.07\n","1133/1496:0.05\n","1134/1496:0.00\n","1135/1496:0.73\n","1136/1496:0.82\n","1137/1496:0.11\n","1138/1496:0.18\n","1139/1496:0.24\n","1140/1496:0.01\n","1141/1496:0.00\n","1142/1496:1.00\n","1143/1496:0.00\n","1144/1496:0.00\n","1145/1496:0.41\n","1146/1496:0.00\n","1147/1496:0.12\n","1148/1496:0.00\n","1149/1496:0.00\n","1150/1496:0.18\n","1151/1496:0.00\n","1152/1496:0.00\n","1153/1496:0.17\n","1154/1496:0.60\n","1155/1496:0.07\n","1156/1496:0.00\n","1157/1496:0.25\n","1158/1496:0.79\n","1159/1496:0.00\n","1160/1496:0.14\n","1161/1496:0.83\n","1162/1496:0.91\n","1163/1496:0.00\n","1164/1496:0.08\n","1165/1496:0.00\n","1166/1496:0.95\n","1167/1496:0.01\n","1168/1496:0.00\n","1169/1496:0.05\n","1170/1496:0.44\n","1171/1496:0.00\n","1172/1496:0.00\n","1173/1496:0.31\n","1174/1496:0.14\n","1175/1496:0.24\n","1176/1496:0.68\n","1177/1496:0.22\n","1178/1496:0.01\n","1179/1496:0.00\n","1180/1496:0.05\n","1181/1496:0.19\n","1182/1496:0.18\n","1183/1496:0.16\n","1184/1496:0.36\n","1185/1496:0.01\n","1186/1496:0.00\n","1187/1496:0.00\n","1188/1496:0.03\n","1189/1496:0.00\n","1190/1496:0.00\n","1191/1496:0.13\n","1192/1496:0.56\n","1193/1496:0.36\n","1194/1496:0.76\n","1195/1496:0.00\n","1196/1496:0.39\n","1197/1496:0.04\n","1198/1496:0.55\n","1199/1496:0.00\n","1200/1496:0.00\n","1201/1496:0.01\n","1202/1496:0.58\n","1203/1496:0.00\n","1204/1496:0.00\n","1205/1496:0.41\n","1206/1496:0.05\n","1207/1496:0.09\n","1208/1496:0.00\n","1209/1496:0.78\n","1210/1496:0.09\n","1211/1496:0.00\n","1212/1496:0.00\n","1213/1496:0.09\n","1214/1496:0.88\n","1215/1496:0.13\n","1216/1496:0.00\n","1217/1496:0.05\n","1218/1496:0.00\n","1219/1496:0.00\n","1220/1496:0.02\n","1221/1496:0.08\n","1222/1496:0.00\n","1223/1496:0.03\n","1224/1496:0.05\n","1225/1496:0.01\n","1226/1496:0.00\n","1227/1496:0.64\n","1228/1496:0.00\n","1229/1496:1.00\n","1230/1496:0.00\n","1231/1496:0.57\n","1232/1496:0.00\n","1233/1496:0.05\n","1234/1496:0.14\n","1235/1496:0.00\n","1236/1496:0.10\n","1237/1496:0.01\n","1238/1496:0.00\n","1239/1496:0.00\n","1240/1496:0.00\n","1241/1496:0.02\n","1242/1496:0.19\n","1243/1496:1.00\n","1244/1496:0.83\n","1245/1496:0.99\n","1246/1496:0.02\n","1247/1496:0.12\n","1248/1496:0.00\n","1249/1496:1.00\n","1250/1496:0.08\n","1251/1496:0.23\n","1252/1496:0.25\n","1253/1496:0.19\n","1254/1496:0.91\n","1255/1496:0.09\n","1256/1496:0.00\n","1257/1496:0.00\n","1258/1496:0.03\n","1259/1496:0.00\n","1260/1496:0.62\n","1261/1496:0.43\n","1262/1496:0.02\n","1263/1496:0.00\n","1264/1496:0.00\n","1265/1496:0.04\n","1266/1496:1.00\n","1267/1496:0.15\n","1268/1496:0.41\n","1269/1496:0.00\n","1270/1496:0.00\n","1271/1496:0.10\n","1272/1496:0.05\n","1273/1496:0.02\n","1274/1496:0.01\n","1275/1496:0.10\n","1276/1496:0.24\n","1277/1496:0.21\n","1278/1496:0.00\n","1279/1496:0.60\n","1280/1496:0.32\n","1281/1496:0.01\n","1282/1496:0.01\n","1283/1496:0.00\n","1284/1496:0.18\n","1285/1496:0.28\n","1286/1496:0.08\n","1287/1496:0.22\n","1288/1496:0.53\n","1289/1496:0.11\n","1290/1496:1.00\n","1291/1496:0.18\n","1292/1496:0.28\n","1293/1496:0.60\n","1294/1496:1.00\n","1295/1496:0.10\n","1296/1496:0.60\n","1297/1496:0.24\n","1298/1496:0.00\n","1299/1496:0.61\n","1300/1496:0.17\n","1301/1496:0.45\n","1302/1496:0.11\n","1303/1496:0.13\n","1304/1496:0.00\n","1305/1496:0.12\n","1306/1496:0.00\n","1307/1496:0.11\n","1308/1496:0.80\n","1309/1496:0.49\n","1310/1496:0.01\n","1311/1496:0.00\n","1312/1496:0.08\n","1313/1496:0.01\n","1314/1496:0.00\n","1315/1496:0.01\n","1316/1496:0.23\n","1317/1496:0.16\n","1318/1496:0.05\n","1319/1496:0.04\n","1320/1496:0.01\n","1321/1496:0.08\n","1322/1496:0.00\n","1323/1496:0.00\n","1324/1496:0.05\n","1325/1496:0.00\n","1326/1496:0.77\n","1327/1496:0.05\n","1328/1496:0.20\n","1329/1496:0.12\n","1330/1496:1.00\n","1331/1496:0.00\n","1332/1496:1.00\n","1333/1496:0.00\n","1334/1496:1.00\n","1335/1496:0.09\n","1336/1496:0.00\n","1337/1496:1.00\n","1338/1496:0.89\n","1339/1496:0.77\n","1340/1496:0.85\n","1341/1496:0.05\n","1342/1496:1.00\n","1343/1496:0.11\n","1344/1496:0.45\n","1345/1496:0.67\n","1346/1496:0.00\n","1347/1496:0.01\n","1348/1496:1.00\n","1349/1496:0.51\n","1350/1496:0.38\n","1351/1496:0.04\n","1352/1496:0.00\n","1353/1496:0.07\n","1354/1496:0.18\n","1355/1496:0.82\n","1356/1496:0.00\n","1357/1496:0.00\n","1358/1496:0.86\n","1359/1496:0.00\n","1360/1496:0.00\n","1361/1496:0.12\n","1362/1496:0.05\n","1363/1496:0.43\n","1364/1496:0.00\n","1365/1496:0.05\n","1366/1496:0.75\n","1367/1496:0.19\n","1368/1496:0.86\n","1369/1496:0.59\n","1370/1496:0.00\n","1371/1496:0.00\n","1372/1496:0.12\n","1373/1496:0.06\n","1374/1496:0.00\n","1375/1496:0.00\n","1376/1496:0.28\n","1377/1496:0.03\n","1378/1496:0.43\n","1379/1496:0.00\n","1380/1496:0.00\n","1381/1496:0.99\n","1382/1496:1.00\n","1383/1496:0.46\n","1384/1496:0.00\n","1385/1496:0.85\n","1386/1496:0.01\n","1387/1496:0.00\n","1388/1496:0.52\n","1389/1496:0.17\n","1390/1496:0.25\n","1391/1496:0.59\n","1392/1496:0.00\n","1393/1496:0.07\n","1394/1496:0.28\n","1395/1496:0.07\n","1396/1496:0.83\n","1397/1496:0.06\n","1398/1496:0.04\n","1399/1496:0.31\n","1400/1496:1.00\n","1401/1496:0.01\n","1402/1496:0.04\n","1403/1496:0.06\n","1404/1496:0.85\n","1405/1496:0.08\n","1406/1496:0.83\n","1407/1496:0.42\n","1408/1496:0.41\n","1409/1496:0.00\n","1410/1496:0.03\n","1411/1496:0.86\n","1412/1496:0.85\n","1413/1496:0.01\n","1414/1496:0.12\n","1415/1496:0.00\n","1416/1496:0.96\n","1417/1496:1.00\n","1418/1496:0.00\n","1419/1496:0.11\n","1420/1496:0.82\n","1421/1496:0.05\n","1422/1496:0.94\n","1423/1496:0.04\n","1424/1496:0.00\n","1425/1496:0.89\n","1426/1496:0.39\n","1427/1496:0.00\n","1428/1496:0.36\n","1429/1496:0.07\n","1430/1496:0.68\n","1431/1496:0.32\n","1432/1496:0.07\n","1433/1496:0.00\n","1434/1496:0.40\n","1435/1496:0.00\n","1436/1496:0.02\n","1437/1496:0.04\n","1438/1496:0.00\n","1439/1496:0.81\n","1440/1496:0.08\n","1441/1496:0.01\n","1442/1496:0.31\n","1443/1496:0.02\n","1444/1496:0.02\n","1445/1496:0.01\n","1446/1496:1.00\n","1447/1496:0.01\n","1448/1496:0.05\n","1449/1496:0.06\n","1450/1496:0.00\n","1451/1496:0.04\n","1452/1496:0.03\n","1453/1496:0.05\n","1454/1496:0.54\n","1455/1496:0.81\n","1456/1496:0.87\n","1457/1496:0.87\n","1458/1496:1.00\n","1459/1496:1.00\n","1460/1496:0.01\n","1461/1496:0.02\n","1462/1496:0.57\n","1463/1496:0.00\n","1464/1496:0.79\n","1465/1496:0.56\n","1466/1496:1.00\n","1467/1496:0.76\n","1468/1496:0.35\n","1469/1496:0.01\n","1470/1496:0.45\n","1471/1496:0.01\n","1472/1496:0.07\n","1473/1496:0.00\n","1474/1496:0.00\n","1475/1496:0.04\n","1476/1496:1.00\n","1477/1496:0.55\n","1478/1496:0.00\n","1479/1496:0.12\n","1480/1496:0.00\n","1481/1496:0.48\n","1482/1496:0.11\n","1483/1496:0.67\n","1484/1496:0.01\n","1485/1496:0.80\n","1486/1496:0.43\n","1487/1496:0.01\n","1488/1496:0.42\n","1489/1496:0.95\n","1490/1496:0.68\n","1491/1496:0.00\n","1492/1496:0.06\n","1493/1496:0.80\n","1494/1496:0.08\n","1495/1496:0.16\n"]}]},{"cell_type":"markdown","source":["##hum list: very long list of values"],"metadata":{"id":"lMSj7JSOBZp4"}},{"cell_type":"code","source":["\n","if use_hum_list == True:\n","  hum_string = \"\"\"\n","  0.02\n","  0.05\n","  0.0\n","  0.45\n","  0.0\n","  0.0\n","  0.0\n","  1.0\n","  0.09\n","  0.01\n","  0.1\n","  0.36\n","  0.01\n","  0.0\n","  0.02\n","  0.11\n","  0.0\n","  0.0\n","  0.0\n","  1.0\n","  0.96\n","  0.55\n","  0.01\n","  0.0\n","  0.0\n","  0.12\n","  0.44\n","  0.18\n","  0.01\n","  0.57\n","  0.45\n","  0.99\n","  0.0\n","  0.43\n","  0.1\n","  0.58\n","  0.88\n","  0.01\n","  0.33\n","  0.23\n","  1.0\n","  1.0\n","  0.01\n","  0.21\n","  0.09\n","  0.68\n","  0.01\n","  0.36\n","  0.1\n","  1.0\n","  0.0\n","  0.0\n","  1.0\n","  0.03\n","  0.77\n","  0.05\n","  0.05\n","  0.37\n","  0.0\n","  0.09\n","  0.39\n","  0.09\n","  0.0\n","  0.56\n","  0.24\n","  0.0\n","  0.35\n","  0.0\n","  1.0\n","  0.1\n","  0.07\n","  0.03\n","  0.2\n","  0.19\n","  0.17\n","  0.8\n","  0.19\n","  0.14\n","  0.0\n","  0.06\n","  0.1\n","  0.15\n","  0.0\n","  0.01\n","  0.07\n","  0.0\n","  0.0\n","  0.13\n","  0.03\n","  0.0\n","  0.0\n","  0.16\n","  0.0\n","  1.0\n","  1.0\n","  0.11\n","  0.02\n","  0.61\n","  0.0\n","  0.06\n","  0.99\n","  0.5\n","  0.42\n","  0.07\n","  0.04\n","  0.02\n","  0.19\n","  0.0\n","  0.32\n","  0.51\n","  0.05\n","  0.45\n","  0.28\n","  0.07\n","  0.0\n","  1.0\n","  0.08\n","  0.57\n","  0.0\n","  0.01\n","  0.08\n","  0.34\n","  0.26\n","  0.12\n","  0.03\n","  0.45\n","  0.0\n","  0.0\n","  0.06\n","  0.01\n","  0.28\n","  0.08\n","  1.0\n","  0.0\n","  1.0\n","  0.0\n","  0.0\n","  0.23\n","  0.0\n","  0.07\n","  0.07\n","  0.0\n","  0.0\n","  0.45\n","  0.21\n","  0.24\n","  0.74\n","  0.05\n","  1.0\n","  0.31\n","  0.12\n","  0.04\n","  0.11\n","  0.21\n","  0.01\n","  0.13\n","  0.5\n","  0.0\n","  0.05\n","  0.0\n","  0.56\n","  1.0\n","  0.04\n","  1.0\n","  0.99\n","  0.47\n","  1.0\n","  0.0\n","  0.0\n","  0.85\n","  1.0\n","  0.07\n","  0.0\n","  0.26\n","  0.05\n","  0.0\n","  0.04\n","  0.81\n","  1.0\n","  0.19\n","  0.03\n","  0.84\n","  0.35\n","  0.31\n","  0.51\n","  0.01\n","  0.07\n","  0.45\n","  0.29\n","  0.09\n","  0.12\n","  0.03\n","  0.0\n","  0.01\n","  0.12\n","  0.0\n","  0.08\n","  0.0\n","  0.71\n","  0.46\n","  0.98\n","  0.13\n","  0.18\n","  0.28\n","  0.07\n","  0.33\n","  0.51\n","  0.0\n","  0.15\n","  0.89\n","  0.0\n","  0.21\n","  0.34\n","  0.92\n","  0.84\n","  0.0\n","  0.36\n","  0.0\n","  0.05\n","  0.0\n","  1.0\n","  0.07\n","  0.0\n","  0.0\n","  0.0\n","  0.4\n","  0.11\n","  0.03\n","  0.06\n","  0.97\n","  0.01\n","  0.22\n","  0.0\n","  0.09\n","  0.78\n","  0.15\n","  0.0\n","  0.54\n","  0.05\n","  0.14\n","  0.58\n","  0.0\n","  0.0\n","  0.31\n","  1.0\n","  0.29\n","  0.02\n","  0.99\n","  0.42\n","  0.0\n","  0.05\n","  0.0\n","  0.08\n","  0.0\n","  0.07\n","  0.86\n","  0.0\n","  0.05\n","  0.0\n","  0.78\n","  0.65\n","  0.01\n","  0.01\n","  0.49\n","  0.26\n","  0.01\n","  0.4\n","  1.0\n","  0.05\n","  0.14\n","  0.0\n","  0.75\n","  0.05\n","  0.01\n","  0.05\n","  0.01\n","  0.92\n","  0.04\n","  0.01\n","  0.0\n","  0.07\n","  0.22\n","  0.05\n","  0.03\n","  0.12\n","  0.0\n","  0.0\n","  0.0\n","  0.4\n","  0.39\n","  0.08\n","  1.0\n","  0.01\n","  0.0\n","  0.33\n","  0.47\n","  0.0\n","  0.05\n","  0.0\n","  0.08\n","  0.0\n","  0.16\n","  0.0\n","  0.07\n","  0.0\n","  0.17\n","  1.0\n","  1.0\n","  0.06\n","  0.0\n","  0.19\n","  0.15\n","  0.87\n","  0.06\n","  0.0\n","  0.0\n","  0.05\n","  0.0\n","  0.43\n","  0.27\n","  0.48\n","  1.0\n","  1.0\n","  0.46\n","  0.0\n","  0.01\n","  0.01\n","  0.69\n","  0.0\n","  0.2\n","  0.86\n","  0.01\n","  0.0\n","  0.0\n","  0.8\n","  1.0\n","  0.75\n","  0.0\n","  0.03\n","  0.04\n","  0.13\n","  0.14\n","  0.73\n","  0.0\n","  0.0\n","  0.62\n","  0.32\n","  0.42\n","  0.13\n","  0.0\n","  0.0\n","  0.12\n","  0.08\n","  1.0\n","  0.41\n","  0.0\n","  0.98\n","  0.46\n","  1.0\n","  1.0\n","  0.02\n","  1.0\n","  0.0\n","  0.43\n","  0.9\n","  0.11\n","  0.32\n","  0.32\n","  0.19\n","  0.0\n","  0.0\n","  0.32\n","  0.01\n","  0.0\n","  0.0\n","  0.13\n","  0.05\n","  0.0\n","  0.0\n","  0.06\n","  0.0\n","  0.01\n","  0.67\n","  0.02\n","  0.57\n","  0.78\n","  0.0\n","  0.9\n","  0.0\n","  0.01\n","  0.0\n","  0.05\n","  0.89\n","  0.16\n","  0.96\n","  0.35\n","  0.02\n","  0.0\n","  0.04\n","  0.0\n","  0.04\n","  0.08\n","  0.88\n","  1.0\n","  1.0\n","  1.0\n","  0.51\n","  0.1\n","  1.0\n","  0.0\n","  0.67\n","  0.0\n","  0.16\n","  0.01\n","  0.03\n","  0.1\n","  0.49\n","  0.05\n","  0.11\n","  0.0\n","  0.0\n","  0.01\n","  0.0\n","  0.43\n","  0.0\n","  0.75\n","  0.41\n","  0.06\n","  0.02\n","  0.66\n","  0.86\n","  0.05\n","  0.07\n","  0.45\n","  0.98\n","  0.0\n","  0.14\n","  0.0\n","  0.0\n","  0.4\n","  0.08\n","  0.04\n","  0.78\n","  0.0\n","  0.65\n","  0.11\n","  0.96\n","  0.01\n","  0.64\n","  0.96\n","  0.0\n","  0.0\n","  0.21\n","  0.05\n","  0.28\n","  1.0\n","  0.0\n","  0.24\n","  0.05\n","  1.0\n","  0.0\n","  0.04\n","  1.0\n","  0.01\n","  0.56\n","  0.0\n","  0.0\n","  0.63\n","  0.0\n","  0.07\n","  0.21\n","  0.16\n","  0.0\n","  0.0\n","  0.0\n","  0.15\n","  0.03\n","  0.01\n","  0.0\n","  0.5\n","  0.08\n","  0.0\n","  0.12\n","  0.0\n","  0.05\n","  0.2\n","  0.0\n","  0.14\n","  0.14\n","  0.0\n","  0.4\n","  0.01\n","  0.71\n","  0.0\n","  0.02\n","  0.0\n","  0.0\n","  0.0\n","  0.0\n","  0.01\n","  0.15\n","  0.16\n","  0.06\n","  0.0\n","  0.59\n","  1.0\n","  0.87\n","  0.05\n","  0.0\n","  0.09\n","  0.1\n","  0.18\n","  0.01\n","  0.51\n","  0.09\n","  0.38\n","  0.5\n","  0.05\n","  0.45\n","  0.8\n","  0.07\n","  0.0\n","  0.48\n","  1.0\n","  0.46\n","  0.72\n","  1.0\n","  0.01\n","  0.14\n","  0.0\n","  0.23\n","  0.13\n","  0.11\n","  0.85\n","  1.0\n","  0.99\n","  0.0\n","  0.04\n","  1.0\n","  0.4\n","  0.0\n","  0.0\n","  0.54\n","  0.0\n","  0.0\n","  0.12\n","  0.25\n","  0.0\n","  0.72\n","  1.0\n","  0.0\n","  0.01\n","  0.82\n","  0.01\n","  0.07\n","  0.0\n","  0.0\n","  0.0\n","  0.15\n","  0.0\n","  0.07\n","  0.01\n","  0.65\n","  0.85\n","  0.08\n","  0.09\n","  0.15\n","  0.96\n","  1.0\n","  0.56\n","  0.46\n","  0.95\n","  0.42\n","  0.01\n","  0.32\n","  0.0\n","  0.0\n","  0.41\n","  0.05\n","  0.89\n","  0.08\n","  0.06\n","  0.23\n","  0.35\n","  0.05\n","  0.16\n","  0.0\n","  0.02\n","  0.04\n","  0.0\n","  0.57\n","  0.15\n","  0.05\n","  0.0\n","  0.0\n","  0.07\n","  0.99\n","  0.0\n","  0.07\n","  0.31\n","  0.73\n","  0.92\n","  0.35\n","  0.24\n","  0.45\n","  0.08\n","  0.09\n","  0.05\n","  1.0\n","  0.0\n","  1.0\n","  0.0\n","  0.42\n","  0.0\n","  0.99\n","  0.57\n","  0.23\n","  0.0\n","  0.31\n","  0.88\n","  0.0\n","  0.09\n","  0.96\n","  0.0\n","  0.8\n","  0.03\n","  0.0\n","  0.0\n","  0.07\n","  0.37\n","  0.0\n","  0.05\n","  0.0\n","  0.0\n","  0.0\n","  0.36\n","  0.01\n","  1.0\n","  0.69\n","  0.98\n","  0.15\n","  0.85\n","  0.11\n","  0.0\n","  0.91\n","  0.99\n","  1.0\n","  0.15\n","  0.27\n","  0.0\n","  0.0\n","  0.0\n","  0.0\n","  0.05\n","  0.37\n","  0.0\n","  0.15\n","  0.03\n","  0.0\n","  0.27\n","  0.03\n","  0.02\n","  0.01\n","  0.88\n","  0.29\n","  0.04\n","  0.03\n","  0.04\n","  0.08\n","  0.0\n","  0.02\n","  0.59\n","  0.0\n","  0.04\n","  0.75\n","  0.01\n","  0.09\n","  0.75\n","  0.03\n","  0.05\n","  0.26\n","  0.03\n","  0.45\n","  0.0\n","  0.03\n","  0.1\n","  0.02\n","  0.0\n","  0.71\n","  0.58\n","  0.0\n","  0.0\n","  0.0\n","  0.0\n","  0.0\n","  0.05\n","  0.05\n","  0.51\n","  0.03\n","  0.87\n","  1.0\n","  0.0\n","  0.28\n","  0.0\n","  0.05\n","  0.18\n","  0.28\n","  0.02\n","  0.0\n","  0.25\n","  0.06\n","  0.03\n","  0.13\n","  0.01\n","  0.22\n","  0.08\n","  0.89\n","  0.05\n","  0.01\n","  0.0\n","  0.64\n","  0.36\n","  0.82\n","  0.55\n","  0.99\n","  0.05\n","  0.05\n","  0.05\n","  0.0\n","  0.56\n","  0.0\n","  0.79\n","  0.09\n","  0.0\n","  0.0\n","  0.17\n","  0.04\n","  0.01\n","  0.0\n","  0.69\n","  0.0\n","  0.23\n","  0.1\n","  0.01\n","  0.05\n","  0.07\n","  0.06\n","  1.0\n","  0.13\n","  0.15\n","  0.03\n","  0.79\n","  1.0\n","  0.29\n","  0.07\n","  0.03\n","  0.0\n","  0.57\n","  0.0\n","  0.15\n","  1.0\n","  0.0\n","  0.45\n","  0.1\n","  0.1\n","  0.55\n","  0.06\n","  0.0\n","  0.19\n","  0.0\n","  0.0\n","  0.0\n","  0.56\n","  0.0\n","  0.45\n","  1.0\n","  0.14\n","  0.0\n","  0.8\n","  0.08\n","  1.0\n","  0.15\n","  0.08\n","  0.61\n","  0.63\n","  0.05\n","  0.08\n","  0.07\n","  0.08\n","  0.0\n","  0.0\n","  0.01\n","  0.07\n","  0.79\n","  0.75\n","  0.04\n","  0.0\n","  0.0\n","  0.0\n","  0.01\n","  0.94\n","  0.0\n","  0.76\n","  0.0\n","  0.01\n","  0.05\n","  0.96\n","  0.37\n","  0.14\n","  0.0\n","  0.39\n","  0.87\n","  0.0\n","  0.0\n","  0.79\n","  0.74\n","  0.0\n","  0.49\n","  0.1\n","  0.12\n","  0.0\n","  0.0\n","  0.07\n","  1.0\n","  0.88\n","  0.05\n","  0.0\n","  0.25\n","  0.02\n","  0.83\n","  1.0\n","  0.0\n","  0.15\n","  1.0\n","  0.65\n","  1.0\n","  0.0\n","  0.0\n","  0.01\n","  0.04\n","  0.0\n","  0.0\n","  0.65\n","  0.04\n","  0.05\n","  0.04\n","  0.0\n","  0.68\n","  0.37\n","  0.01\n","  0.0\n","  0.0\n","  0.15\n","  0.0\n","  0.0\n","  0.38\n","  0.99\n","  0.81\n","  0.0\n","  0.0\n","  0.12\n","  0.07\n","  0.86\n","  0.0\n","  0.81\n","  0.12\n","  0.85\n","  0.04\n","  0.0\n","  0.4\n","  0.0\n","  0.01\n","  0.87\n","  0.02\n","  0.08\n","  0.08\n","  0.84\n","  0.0\n","  0.49\n","  0.02\n","  0.0\n","  0.0\n","  0.05\n","  0.0\n","  0.01\n","  0.01\n","  0.08\n","  0.28\n","  0.05\n","  0.08\n","  0.0\n","  0.0\n","  0.01\n","  0.01\n","  0.03\n","  1.0\n","  0.01\n","  0.2\n","  0.33\n","  0.02\n","  0.1\n","  1.0\n","  0.0\n","  0.04\n","  0.05\n","  0.0\n","  0.01\n","  0.0\n","  0.11\n","  0.06\n","  0.6\n","  0.11\n","  0.0\n","  0.0\n","  0.02\n","  0.01\n","  0.0\n","  0.03\n","  0.88\n","  0.9\n","  0.0\n","  1.0\n","  0.05\n","  1.0\n","  0.02\n","  0.0\n","  0.04\n","  0.15\n","  0.89\n","  0.29\n","  0.07\n","  0.0\n","  0.97\n","  0.0\n","  0.12\n","  0.81\n","  0.05\n","  0.0\n","  0.0\n","  0.01\n","  0.0\n","  0.2\n","  0.54\n","  0.8\n","  0.78\n","  0.01\n","  0.29\n","  0.65\n","  0.05\n","  0.98\n","  0.16\n","  0.01\n","  0.03\n","  0.0\n","  0.0\n","  0.72\n","  0.13\n","  0.64\n","  0.0\n","  1.0\n","  0.16\n","  0.18\n","  0.0\n","  0.79\n","  0.51\n","  1.0\n","  0.87\n","  0.02\n","  0.08\n","  0.05\n","  0.0\n","  0.04\n","  0.07\n","  0.53\n","  0.3\n","  0.78\n","  0.34\n","  0.0\n","  0.0\n","  0.04\n","  0.19\n","  0.0\n","  1.0\n","  0.01\n","  0.05\n","  0.0\n","  0.15\n","  0.45\n","  0.01\n","  1.0\n","  0.0\n","  0.03\n","  0.23\n","  0.61\n","  0.45\n","  0.1\n","  1.0\n","  0.01\n","  1.0\n","  0.45\n","  0.02\n","  0.07\n","  0.45\n","  0.06\n","  0.02\n","  0.01\n","  1.0\n","  0.49\n","  0.16\n","  0.15\n","  0.65\n","  0.05\n","  0.23\n","  0.4\n","  0.63\n","  0.67\n","  0.17\n","  0.0\n","  0.0\n","  0.42\n","  0.0\n","  0.01\n","  0.05\n","  0.14\n","  0.9\n","  0.0\n","  0.0\n","  0.0\n","  0.0\n","  1.0\n","  0.11\n","  0.88\n","  0.03\n","  0.0\n","  0.01\n","  0.74\n","  0.0\n","  0.0\n","  1.0\n","  0.26\n","  0.81\n","  0.0\n","  0.0\n","  0.05\n","  0.25\n","  0.0\n","  0.39\n","  0.78\n","  0.05\n","  0.76\n","  0.07\n","  0.0\n","  0.16\n","  0.16\n","  0.0\n","  0.84\n","  1.0\n","  0.0\n","  0.82\n","  0.01\n","  0.0\n","  0.25\n","  0.05\n","  0.0\n","  0.09\n","  0.0\n","  0.35\n","  0.02\n","  0.0\n","  0.01\n","  0.56\n","  0.0\n","  0.01\n","  0.01\n","  0.06\n","  0.46\n","  0.92\n","  0.0\n","  0.07\n","  0.2\n","  0.37\n","  0.23\n","  0.03\n","  0.17\n","  0.88\n","  0.2\n","  0.0\n","  0.07\n","  0.0\n","  0.0\n","  0.05\n","  0.0\n","  0.05\n","  0.15\n","  0.0\n","  0.0\n","  0.05\n","  0.05\n","  0.0\n","  0.0\n","  0.64\n","  0.58\n","  0.05\n","  0.05\n","  0.0\n","  0.1\n","  0.09\n","  0.0\n","  0.01\n","  0.0\n","  0.2\n","  0.05\n","  0.21\n","  0.01\n","  0.0\n","  0.05\n","  0.0\n","  0.27\n","  0.05\n","  0.88\n","  0.0\n","  0.6\n","  0.28\n","  0.06\n","  0.39\n","  0.08\n","  0.01\n","  0.03\n","  0.49\n","  0.0\n","  0.02\n","  0.0\n","  0.07\n","  0.05\n","  0.0\n","  0.73\n","  0.82\n","  0.11\n","  0.18\n","  0.24\n","  0.01\n","  0.0\n","  1.0\n","  0.0\n","  0.0\n","  0.41\n","  0.0\n","  0.12\n","  0.0\n","  0.0\n","  0.18\n","  0.0\n","  0.0\n","  0.17\n","  0.6\n","  0.07\n","  0.0\n","  0.25\n","  0.79\n","  0.0\n","  0.14\n","  0.83\n","  0.91\n","  0.0\n","  0.08\n","  0.0\n","  0.95\n","  0.01\n","  0.0\n","  0.05\n","  0.44\n","  0.0\n","  0.0\n","  0.31\n","  0.14\n","  0.24\n","  0.68\n","  0.22\n","  0.01\n","  0.0\n","  0.05\n","  0.19\n","  0.18\n","  0.16\n","  0.36\n","  0.01\n","  0.0\n","  0.0\n","  0.03\n","  0.0\n","  0.0\n","  0.13\n","  0.56\n","  0.36\n","  0.76\n","  0.0\n","  0.39\n","  0.04\n","  0.55\n","  0.0\n","  0.0\n","  0.01\n","  0.58\n","  0.0\n","  0.0\n","  0.41\n","  0.05\n","  0.09\n","  0.0\n","  0.78\n","  0.09\n","  0.0\n","  0.0\n","  0.09\n","  0.88\n","  0.13\n","  0.0\n","  0.05\n","  0.0\n","  0.0\n","  0.02\n","  0.08\n","  0.0\n","  0.03\n","  0.05\n","  0.01\n","  0.0\n","  0.64\n","  0.0\n","  1.0\n","  0.0\n","  0.57\n","  0.0\n","  0.05\n","  0.14\n","  0.0\n","  0.1\n","  0.01\n","  0.0\n","  0.0\n","  0.0\n","  0.02\n","  0.19\n","  1.0\n","  0.83\n","  0.99\n","  0.02\n","  0.12\n","  0.0\n","  1.0\n","  0.08\n","  0.23\n","  0.25\n","  0.19\n","  0.91\n","  0.09\n","  0.0\n","  0.0\n","  0.03\n","  0.0\n","  0.62\n","  0.43\n","  0.02\n","  0.0\n","  0.0\n","  0.04\n","  1.0\n","  0.15\n","  0.41\n","  0.0\n","  0.0\n","  0.1\n","  0.05\n","  0.02\n","  0.01\n","  0.1\n","  0.24\n","  0.21\n","  0.0\n","  0.6\n","  0.32\n","  0.01\n","  0.01\n","  0.0\n","  0.18\n","  0.28\n","  0.08\n","  0.22\n","  0.53\n","  0.11\n","  1.0\n","  0.18\n","  0.28\n","  0.6\n","  1.0\n","  0.1\n","  0.6\n","  0.24\n","  0.0\n","  0.61\n","  0.17\n","  0.45\n","  0.11\n","  0.13\n","  0.0\n","  0.12\n","  0.0\n","  0.11\n","  0.8\n","  0.49\n","  0.01\n","  0.0\n","  0.08\n","  0.01\n","  0.0\n","  0.01\n","  0.23\n","  0.16\n","  0.05\n","  0.04\n","  0.01\n","  0.08\n","  0.0\n","  0.0\n","  0.05\n","  0.0\n","  0.77\n","  0.05\n","  0.2\n","  0.12\n","  1.0\n","  0.0\n","  1.0\n","  0.0\n","  1.0\n","  0.09\n","  0.0\n","  1.0\n","  0.89\n","  0.77\n","  0.85\n","  0.05\n","  1.0\n","  0.11\n","  0.45\n","  0.67\n","  0.0\n","  0.01\n","  1.0\n","  0.51\n","  0.38\n","  0.04\n","  0.0\n","  0.07\n","  0.18\n","  0.82\n","  0.0\n","  0.0\n","  0.86\n","  0.0\n","  0.0\n","  0.12\n","  0.05\n","  0.43\n","  0.0\n","  0.05\n","  0.75\n","  0.19\n","  0.86\n","  0.59\n","  0.0\n","  0.0\n","  0.12\n","  0.06\n","  0.0\n","  0.0\n","  0.28\n","  0.03\n","  0.43\n","  0.0\n","  0.0\n","  0.99\n","  1.0\n","  0.46\n","  0.0\n","  0.85\n","  0.01\n","  0.0\n","  0.52\n","  0.17\n","  0.25\n","  0.59\n","  0.0\n","  0.07\n","  0.28\n","  0.07\n","  0.83\n","  0.06\n","  0.04\n","  0.31\n","  1.0\n","  0.01\n","  0.04\n","  0.06\n","  0.85\n","  0.08\n","  0.83\n","  0.42\n","  0.41\n","  0.0\n","  0.03\n","  0.86\n","  0.85\n","  0.01\n","  0.12\n","  0.0\n","  0.96\n","  1.0\n","  0.0\n","  0.11\n","  0.82\n","  0.05\n","  0.94\n","  0.04\n","  0.0\n","  0.89\n","  0.39\n","  0.0\n","  0.36\n","  0.07\n","  0.68\n","  0.32\n","  0.07\n","  0.0\n","  0.4\n","  0.0\n","  0.02\n","  0.04\n","  0.0\n","  0.81\n","  0.08\n","  0.01\n","  0.31\n","  0.02\n","  0.02\n","  0.01\n","  1.0\n","  0.01\n","  0.05\n","  0.06\n","  0.0\n","  0.04\n","  0.03\n","  0.05\n","  0.54\n","  0.81\n","  0.87\n","  0.87\n","  1.0\n","  1.0\n","  0.01\n","  0.02\n","  0.57\n","  0.0\n","  0.79\n","  0.56\n","  1.0\n","  0.76\n","  0.35\n","  0.01\n","  0.45\n","  0.01\n","  0.07\n","  0.0\n","  0.0\n","  0.04\n","  1.0\n","  0.55\n","  0.0\n","  0.12\n","  0.0\n","  0.48\n","  0.11\n","  0.67\n","  0.01\n","  0.8\n","  0.43\n","  0.01\n","  0.42\n","  0.95\n","  0.68\n","  0.0\n","  0.06\n","  0.8\n","  0.08\n","  0.16\n","  \"\"\"\n","  hum_list = [float(hum) for hum in hum_string.split()]\n","  try:\n","    assert 'authors' in globals(),'pass'\n","  except:\n","    try:\n","      with open(data_path_in, 'r', encoding='utf-8') as f:\n","        authors = json.load(f)\n","    except:\n","      raise Exception('could not load authors or data_path_in')\n","  for author,hum in zip(authors,hum_list):\n","    author['labels']['humility'] = hum\n","\n","  print('Loaded data from list')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mG2iDK1KBc2A","executionInfo":{"status":"ok","timestamp":1747707367708,"user_tz":-120,"elapsed":59,"user":{"displayName":"Geran De Rijk","userId":"14984877830666793525"}},"outputId":"c9b48c5e-bfe2-4276-b186-e857e5d56b45"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded data from list\n"]}]},{"cell_type":"markdown","source":["##end hum list"],"metadata":{"id":"UNXLupbQEw_V"}},{"cell_type":"markdown","source":["prepare training data"],"metadata":{"id":"SgIeqZlwhhZ4"}},{"cell_type":"code","source":["\n","def label_to_ordinal(labels): # train is neuro, keeps neuro as neuro\n","    low_threshold = 0.33\n","    high_threshold = 0.66\n","    for key, value in labels.items():\n","      if value <= low_threshold:\n","          labels[key] = 0\n","      elif value <= high_threshold:\n","          labels[key] = 1\n","      else:\n","          labels[key] = 2\n","    return labels\n","\n","def change_capital_order(data):\n","    new_data = []\n","    for author in data:\n","        author_id = author['id']\n","        comments = author['comments']\n","        labels = author['labels']\n","        new_labels = {\n","            'openness': labels['openness'],\n","            'conscientiousness': labels['conscientiousness'],\n","            'extraversion': labels['extraversion'],\n","            'agreeableness': labels['agreeableness'],\n","            'neuroticism': labels['neuroticism'],\n","            'humility': labels['humility'] if 'humility' in labels else labels.get('Humility',0)\n","        }\n","        new_dict = {\n","            'id': author_id,\n","            'comments': comments,\n","            'labels': new_labels\n","        }\n","        new_data.append(new_dict)\n","    return new_data\n","\n","# test func\n","def test_data_transform(path):\n","    '''\n","    converts emo stab into neuroticism\n","    q1-3 into comments as list\n","    traits -> labels (dict)\n","    rows into dicts\n","    '''\n","    df = pd.read_csv(path)\n","    cols = ['Openness', 'Conscientiousness', 'Extraversion', 'Agreeableness', 'Humility']\n","    conversion = {\n","        'low': 0,\n","        'medium': 1,\n","        'high': 2\n","    }\n","    df[cols] = df[cols].apply(lambda col: col.map(conversion))\n","\n","    #swap es to neuro\n","    conversion_es_neuro = {\n","        'low': 2,\n","        'medium': 1,\n","        'high': 0\n","    }\n","    df['Emotional stability'] = df['Emotional stability'].map(conversion_es_neuro)\n","\n","    data = []\n","    for idx, row in df.iterrows():\n","        comments = [row[col] for col in ['Q1','Q2','Q3']]\n","        labels = {\n","            'openness': row['Openness'],\n","            'conscientiousness': row['Conscientiousness'],\n","            'extraversion': row['Extraversion'],\n","            'agreeableness': row['Agreeableness'],\n","            'neuroticism': row['Emotional stability'],\n","            'humility': row['Humility']\n","        }\n","        new_dict ={\n","            'id': row['id'],\n","            'comments': comments,\n","            'labels': labels\n","        }\n","        data.append(new_dict)\n","    return data"],"metadata":{"id":"JCk-mDDwAICT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# training prep\n","print('Preparing data for training...')\n","#train data; change floats to ordinal\n","for author in authors:\n","    new_labels = label_to_ordinal(author['labels'])\n","    author['labels'] = new_labels\n","#train change order to match test\n","full_train_data = change_capital_order(authors)\n","\n","#val\n","try:\n","  val_path = f'{folder}/data/val_data.csv'\n","except:\n","  val_path = r'/content/drive/MyDrive/digital text analysis/NLP/shared task/data/val_data.csv'\n","\n","test_data = test_data_transform(val_path)\n","print('\\nFun fact! Someone quoted Moby Dick all over the validation set! ^^')\n","print(f\"\\'{test_data[24]['comments'][0]}\\'\")\n","print(f\"\\'{test_data[24]['comments'][1]}\\'\")\n","print(f\"\\'{test_data[24]['comments'][2]}\\'\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vT2wbImPfneM","executionInfo":{"status":"ok","timestamp":1747707426670,"user_tz":-120,"elapsed":584,"user":{"displayName":"Geran De Rijk","userId":"14984877830666793525"}},"outputId":"08c659b2-19df-4803-b4e0-26572e69b67e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Preparing data for training...\n","\n","Fun fact! Someone quoted Moby Dick all over my validation set! ^^ (id: 25)\n","'Latin from the books of the Laws of England, which taken along with the context, means, that of all whales captured by anybody on the coast of that land, the King, as Honorary Grand Harpooneer, must have the head, and the Queen be respectfully presented with the tail. A division which, in the whale, is much like halving an apple; there is no intermediate remainder. Now as this law, under a modified form, is to this day in force in England; and as it offers in various respects a strange anomaly touching the general law of Fast and Loose-Fish, it is here treated of in a separate chapter, on the same courteous principle that prompts the English railways to be at the expense of a separate car, specially reserved for the accommodation of royalty. In the first place, in curious proof of the fact that the above-mentioned law is still in force, I proceed to lay before you a circumstance that happened within the last two years.'\n","'It seems that some honest mariners of Dover, or Sandwich, or some one of the Cinque Ports, had after a hard chase succeeded in killing and beaching a fine whale which they had originally descried afar off from the shore. Now the Cinque Ports are partially or somehow under the jurisdiction of a sort of policeman or beadle, called a Lord Warden. Holding the office directly from the crown, I believe, all the royal emoluments incident to the Cinque Port territories become by assignment his. By some writers this office is called a sinecure. But not so. Because the Lord Warden is busily employed at times in fobbing his perquisites; which are his chiefly by virtue of that same fobbing of them.'\n","'Now when these poor sun-burnt mariners, bare-footed, and with their trowsers rolled high up on their eely legs, had wearily hauled their fat fish high and dry, promising themselves a good £150 from the precious oil and bone; and in fantasy sipping rare tea with their wives, and good ale with their cronies, upon the strength of their respective shares; up steps a very learned and most Christian and charitable gentleman, with a copy of Blackstone under his arm; and laying it upon the whale's head, he says—\"Hands off! this fish, my masters, is a Fast-Fish. I seize it as the Lord Warden's.\" Upon this the poor mariners in their respectful consternation—so truly English—knowing not what to say, fall to vigorously scratching their heads all round; meanwhile ruefully glancing from the whale to the stranger. But that did in nowise mend the matter, or at all soften the hard heart of the learned gentleman with the copy of Blackstone. At length one of them, after long scratching about for his ideas, made bold to speak,'\n"]}]},{"cell_type":"code","source":["#save #TEMP #FIX\n","try:\n","  if save == True:\n","    print('\\nSaving...')\n","    with open('train_data.json', 'w', encoding='utf-8') as f:\n","        json.dump(full_train_data,f)\n","\n","    with open('val_data.json', 'w', encoding='utf-8') as f:\n","        json.dump(val_data_holdout,f)\n","  else:\n","    pass\n","except:\n","  pass"],"metadata":{"id":"jNeQiZojf758"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["I used this code to check how good the prompting method was... it was ok-ish. (skipped in from_nb)"],"metadata":{"id":"kGu-WZbfZswL"}},{"cell_type":"code","source":["if from_nb == 'local':\n","  %pip install outlines\n","  #load data\n","  import pandas as pd\n","  path_val = r'/content/drive/MyDrive/digital text analysis/NLP/shared task/data/val_data_realvalued.csv'\n","  df_val = pd.read_csv(path_val)\n","\n","  def rework_dataframe(df):\n","    df['Text'] = df[['Q1', 'Q2', 'Q3']].values.tolist()\n","    df['Humility'] = df['Humility']/100\n","    df_reworked = df[['Text','Humility']]\n","    return df_reworked\n","\n","  df_val = rework_dataframe(df_val)\n","\n","\n","  from outlines import models\n","\n","  model_name = \"meta-llama/Llama-3.2-3B-Instruct\"\n","  model = outlines.models.transformers(model_name, device='cuda')\n","\n","\n","  pattern = r'0\\.\\d{2}|1\\.00'\n","  generator = outlines.generate.regex(model, pattern)\n","\n","\n","  #few\n","  for index, row in df_val.iterrows():\n","    if index == 0:\n","      ex_text1 = row['Text']\n","      ex_hum1 = row['Humility']\n","    elif index == 1:\n","      ex_text2 = row['Text']\n","      ex_hum2 = row['Humility']\n","    elif index == 2:\n","      ex_text3 = row['Text']\n","      ex_hum3 = row['Humility']\n","    else:\n","      break\n","  print(ex_text1)\n","  print(ex_hum1)\n","  print(ex_text2)\n","  print(ex_hum2)\n","  print(ex_text3)\n","  print(ex_hum3)\n","\n","\n","\n","  from tqdm import tqdm\n","  import pandas as pd\n","  #few shot examples:\n","  import pandas as pd\n","\n","\n","  prompt = f\"\"\"\n","  You are an expert in personality psychology. Your task is to rate the humility of a person based on their comments. Begin your answer with the score (a number between 0.00 (not humble) and 1.00 (very humble)).\n","  Indicators of humility are:\n","  Sincerity\n","  Fairness\n","  Greed-Avoidance\n","  Modesty\n","\n","  Here are some examples of accurate scores:\n","  Example 1:\n","  Comments:{ex_text1}\n","  Humility:{ex_hum1}\n","  Example 2:\n","  Comments:{ex_text2}\n","  Humility:{ex_hum2}\n","  Example 3:\n","  Comments:{ex_text3}\n","  Humility:{ex_hum3}\n","\n","  What level of humility does the following person have?\n","  \"\"\"\n","\n","  pred_labels = []\n","  for index, row in tqdm(df_val.iterrows()):\n","    if index <= 2:\n","      continue\n","    comments = row['Text']\n","    final_prompt = prompt + f'Comments:{comments}' + '\\n' + 'Humility:'\n","    answer = generator(final_prompt, max_tokens=4)\n","    pred_labels.append(answer)\n","    print(answer)\n","\n","\n","\n","\n","  true_labels = []\n","  for index, row in df_val.iterrows():\n","    if index <= 2:\n","      continue\n","    else:\n","      true_labels.append(row['Humility'])\n","\n","\n","  from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n","  import numpy as np\n","\n","  # Calculate Mean Absolute Error\n","  mae = mean_absolute_error(true_labels, pred_labels)\n","  print(f\"Mean Absolute Error: {mae}\")\n","\n","  # Calculate Mean Squared Error\n","  mse = mean_squared_error(true_labels, pred_labels)\n","  print(f\"Mean Squared Error: {mse}\")\n","\n","  # Calculate Root Mean Squared Error\n","  rmse = np.sqrt(mse)\n","  print(f\"Root Mean Squared Error: {rmse}\")\n","\n","  # Calculate R-squared\n","  r2 = r2_score(true_labels, pred_labels)\n","  print(f\"R-squared: {r2}\")\n","\n","else:\n","  print('Skipped testing portion of notebook.')"],"metadata":{"id":"Iwh-To0qZp9M"},"execution_count":null,"outputs":[]}]}